{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inderjeet78/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-6930bf08c5c8>:17: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/inderjeet78/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/inderjeet78/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/inderjeet78/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/inderjeet78/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "(5638, 785)\n",
      "(49362, 785)\n",
      "[[0. 0. 0. ... 0. 0. 7.]\n",
      " [0. 0. 0. ... 0. 0. 4.]\n",
      " [0. 0. 0. ... 0. 0. 6.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 5.]\n",
      " [0. 0. 0. ... 0. 0. 6.]\n",
      " [0. 0. 0. ... 0. 0. 8.]]\n",
      "(49362, 785)\n",
      "(321, 785)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "137.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "# Training data prepration\n",
    "\n",
    "c1_x = mnist.train.images[mnist.train.labels==3]\n",
    "c1_y = mnist.train.labels[mnist.train.labels==3]\n",
    "c1_y = c1_y[:,None]\n",
    "other_x = mnist.train.images[mnist.train.labels!=3]\n",
    "other_y = mnist.train.labels[mnist.train.labels!=3]\n",
    "other_y=other_y[:,None]\n",
    "\n",
    "np.random.seed(42)\n",
    "c1 = np.concatenate((c1_x,c1_y),axis=1)\n",
    "others = np.concatenate((other_x,other_y), axis=1)\n",
    "print(c1.shape)\n",
    "print(others.shape)\n",
    "print(others)\n",
    "np.random.shuffle(others)\n",
    "others = np.array(others)\n",
    "print(others.shape)\n",
    "others321 = others[0:321,:]\n",
    "print(others321.shape)\n",
    "train = np.concatenate((c1,others321),axis=0)\n",
    "np.random.shuffle(train)\n",
    "X_train = train[:,0:-1]\n",
    "Y_train = train[:,-1]\n",
    "Y_train[Y_train==0]=1\n",
    "Y_train[Y_train==3]=0\n",
    "Y_train[Y_train!=0]=1\n",
    "\n",
    "sum(Y_train)\n",
    "\n",
    "# Validation data prepration\n",
    "\n",
    "np.random.seed(42)\n",
    "valX_ones = mnist.validation.images[mnist.validation.labels==3]\n",
    "valY_ones = mnist.validation.labels[mnist.validation.labels==3]\n",
    "valX_others = mnist.validation.images[mnist.validation.labels!=3]\n",
    "valY_others = mnist.validation.labels[mnist.validation.labels!=3]\n",
    "valY_ones = valY_ones[:,None]\n",
    "valY_others = valY_others[:,None]\n",
    "val_ones = np.concatenate((valX_ones,valY_ones),axis=1)\n",
    "val_others = np.concatenate((valX_others,valY_others),axis=1)\n",
    "np.random.shuffle(val_others)\n",
    "val_others137 = val_others[0:137,:]\n",
    "val = np.concatenate((val_ones,val_others137),axis=0)\n",
    "np.random.shuffle(val)\n",
    "valX = val[:,0:-1]\n",
    "valY = val[:,-1]\n",
    "valY[valY==0]=1\n",
    "valY[valY==3]=0\n",
    "valY[valY!=0]=1\n",
    "\n",
    "sum(valY)\n",
    "\n",
    "# Test data prepration\n",
    "\n",
    "np.random.seed(42)\n",
    "testX_ones = mnist.test.images[mnist.test.labels==3]\n",
    "testY_ones = mnist.test.labels[mnist.test.labels==3]\n",
    "testX_others = mnist.test.images[mnist.test.labels!=3]\n",
    "testY_others = mnist.test.labels[mnist.test.labels!=3]\n",
    "testY_ones = testY_ones[:,None]\n",
    "testY_others = testY_others[:,None]\n",
    "test_ones = np.concatenate((testX_ones,testY_ones),axis=1)\n",
    "test_others = np.concatenate((testX_others,testY_others),axis=1)\n",
    "np.random.shuffle(test_others)\n",
    "test_others137 = test_others[0:137,:]\n",
    "test = np.concatenate((test_ones,test_others137),axis=0)\n",
    "np.random.shuffle(test)\n",
    "testX = test[:,0:-1]\n",
    "testY = test[:,-1]\n",
    "testY[testY==0]=1\n",
    "testY[testY==3]=0\n",
    "testY[testY!=0]=1\n",
    "\n",
    "sum(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3600x216 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 25\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(14,n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    sample_image = X_train[index].reshape(28, 28)\n",
    "    plt.imshow(sample_image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:n_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-d9e33cb66a21>:32: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From <ipython-input-4-d9e33cb66a21>:67: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32, name=\"X\")\n",
    "\n",
    "caps1_n_maps = 32\n",
    "caps1_n_caps = caps1_n_maps * 6 * 6  # 1152 primary capsules\n",
    "caps1_n_dims = 8\n",
    "\n",
    "conv1_params = {\n",
    "    \"filters\": 256,\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 1,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu,\n",
    "}\n",
    "\n",
    "conv2_params = {\n",
    "    \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 2,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\n",
    "\n",
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
    "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)\n",
    "\n",
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                       name=\"caps1_raw\")\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector\n",
    "\n",
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")\n",
    "\n",
    "caps2_n_caps = 2\n",
    "caps2_n_dims = 16\n",
    "\n",
    "init_sigma = 0.1\n",
    "\n",
    "W_init = tf.random_normal(\n",
    "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "W = tf.Variable(W_init, name=\"W\")\n",
    "\n",
    "batch_size = tf.shape(X)[0]\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")\n",
    "\n",
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                       name=\"caps1_output_expanded\")\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                   name=\"caps1_output_tile\")\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                             name=\"caps1_output_tiled\")\n",
    "\n",
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
    "                            name=\"caps2_predicted\")\n",
    "\n",
    "# Dynamic Routing algorithm\n",
    "# Round 1\n",
    "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
    "                       dtype=np.float32, name=\"raw_weights\")\n",
    "routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")\n",
    "\n",
    "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
    "                                   name=\"weighted_predictions\")\n",
    "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
    "                             name=\"weighted_sum\")\n",
    "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
    "                              name=\"caps2_output_round_1\")\n",
    "\n",
    "caps2_output_round_1_tiled = tf.tile(\n",
    "    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_1_tiled\")\n",
    "\n",
    "agreement1 = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
    "                      transpose_a=True, name=\"agreement1\")\n",
    "# Round 2\n",
    "# Routing weight update\n",
    "raw_weights_round_2 = tf.add(raw_weights, agreement1,\n",
    "                             name=\"raw_weights_round_2\")\n",
    "routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_2\")\n",
    "weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_2\")\n",
    "weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_2\")\n",
    "caps2_output_round_2 = squash(weighted_sum_round_2,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_2\")\n",
    "caps2_output_round_2_tiled = tf.tile(\n",
    "    caps2_output_round_2, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_2_tiled\")\n",
    "\n",
    "agreement2 = tf.matmul(caps2_predicted, caps2_output_round_2_tiled,\n",
    "                      transpose_a=True, name=\"agreement2\")\n",
    "\n",
    "# Round 3\n",
    "# Routing weight update\n",
    "raw_weights_round_3 = tf.add(raw_weights_round_2, agreement2,\n",
    "                             name=\"raw_weights_round_3\")\n",
    "routing_weights_round_3 = tf.nn.softmax(raw_weights_round_3,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_3\")\n",
    "weighted_predictions_round_3 = tf.multiply(routing_weights_round_3,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_3\")\n",
    "weighted_sum_round_3 = tf.reduce_sum(weighted_predictions_round_3,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_3\")\n",
    "caps2_output_round_3 = squash(weighted_sum_round_3,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_3\")\n",
    "caps2_output_round_3_tiled = tf.tile(\n",
    "    caps2_output_round_3, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_3_tiled\")\n",
    "\n",
    "agreement3 = tf.matmul(caps2_predicted, caps2_output_round_3_tiled,\n",
    "                      transpose_a=True, name=\"agreement3\")\n",
    "\n",
    "# Round 4\n",
    "# Routing weight update\n",
    "raw_weights_round_4 = tf.add(raw_weights_round_3, agreement3,\n",
    "                             name=\"raw_weights_round_4\")\n",
    "routing_weights_round_4 = tf.nn.softmax(raw_weights_round_4,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_4\")\n",
    "weighted_predictions_round_4 = tf.multiply(routing_weights_round_4,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_4\")\n",
    "weighted_sum_round_4 = tf.reduce_sum(weighted_predictions_round_4,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_4\")\n",
    "caps2_output_round_4 = squash(weighted_sum_round_4,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_4\")\n",
    "\"\"\"caps2_output_round_4_tiled = tf.tile(\n",
    "    caps2_output_round_4, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_4_tiled\")\n",
    "\n",
    "agreement4 = tf.matmul(caps2_predicted, caps2_output_round_4_tiled,\n",
    "                      transpose_a=True, name=\"agreement3\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "caps2_output = caps2_output_round_4\n",
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)\n",
    "\n",
    "y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")\n",
    "\n",
    "\n",
    "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n",
    "\n",
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
    "\n",
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")\n",
    "\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5\n",
    "\n",
    "T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")\n",
    "\n",
    "caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
    "                              name=\"caps2_output_norm\")\n",
    "\n",
    "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
    "                              name=\"present_error_raw\")\n",
    "present_error = tf.reshape(present_error_raw, shape=(-1, 2),\n",
    "                           name=\"present_error\")\n",
    "present_error\n",
    "\n",
    "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
    "                             name=\"absent_error_raw\")\n",
    "absent_error = tf.reshape(absent_error_raw, shape=(-1, 2),\n",
    "                          name=\"absent_error\")\n",
    "\n",
    "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
    "           name=\"L\")\n",
    "\n",
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n",
    "\n",
    "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
    "                                               name=\"mask_with_labels\")\n",
    "\n",
    "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                                 lambda: y,        # if True\n",
    "                                 lambda: y_pred,   # if False\n",
    "                                 name=\"reconstruction_targets\")\n",
    "\n",
    "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
    "                                 depth=caps2_n_caps,\n",
    "                                 name=\"reconstruction_mask\")\n",
    "\n",
    "reconstruction_mask_reshaped = tf.reshape(\n",
    "    reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],\n",
    "    name=\"reconstruction_mask_reshaped\")\n",
    "\n",
    "caps2_output_masked = tf.multiply(\n",
    "    caps2_output, reconstruction_mask_reshaped,\n",
    "    name=\"caps2_output_masked\")\n",
    "\n",
    "decoder_input = tf.reshape(caps2_output_masked,\n",
    "                           [-1, caps2_n_caps * caps2_n_dims],\n",
    "                           name=\"decoder_input\")\n",
    "\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 1024\n",
    "n_output = 28 * 28\n",
    "\n",
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
    "                                     activation=tf.nn.sigmoid,\n",
    "                                     name=\"decoder_output\")\n",
    "\n",
    "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "squared_difference = tf.square(X_flat - decoder_output,\n",
    "                               name=\"squared_difference\")\n",
    "reconstruction_loss = tf.reduce_mean(squared_difference,\n",
    "                                    name=\"reconstruction_loss\")\n",
    "\n",
    "alpha = 0.0005\n",
    "\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")\n",
    "\n",
    "\n",
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Val accuracy: 87.0000%  Loss: 0.057572 (improved)\n",
      "Epoch: 2  Val accuracy: 96.8333%  Loss: 0.021683 (improved)\n",
      "Epoch: 3  Val accuracy: 98.6667%  Loss: 0.016138 (improved)\n",
      "Epoch: 4  Val accuracy: 98.8333%  Loss: 0.013310 (improved)\n",
      "Epoch: 5  Val accuracy: 98.8333%  Loss: 0.014076\n",
      "Epoch: 6  Val accuracy: 98.3333%  Loss: 0.015233\n",
      "Epoch: 7  Val accuracy: 97.8333%  Loss: 0.015781\n",
      "Epoch: 8  Val accuracy: 98.1667%  Loss: 0.015679\n",
      "Epoch: 9  Val accuracy: 98.5000%  Loss: 0.014203\n",
      "Epoch: 10  Val accuracy: 98.6667%  Loss: 0.010286 (improved)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 50\n",
    "restore_checkpoint = False\n",
    "n_iterations_per_epoch = len(X_train) // batch_size\n",
    "n_iterations_validation = len(valX) // batch_size\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network3\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            X_batch = X_train[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "            y_batch = Y_train[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "            # Run the training operation and measure the loss:\n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch,\n",
    "                           mask_with_labels: True})\n",
    "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                      iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "\n",
    "        # At the end of each epoch,  \n",
    "        # measure the validation loss and accuracy:\n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        for iteration in range(1, n_iterations_validation + 1):\n",
    "            X_batch = valX[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "            y_batch = valY[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "            loss_val, acc_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                               y: y_batch})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "        # And save the model if it improved: \n",
    "        \n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network3\n",
      "Final test accuracy: 99.0909%  Loss: 0.006981 \n"
     ]
    }
   ],
   "source": [
    "n_iterations_test = len(testX) // batch_size\n",
    "checkpoint_path = \"./my_capsule_network3\"\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    pred = []\n",
    "    loss_tests = []\n",
    "    acc_tests = []\n",
    "    for iteration in range(1, n_iterations_test + 1):\n",
    "        X_batch = testX[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "        y_batch = testY[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "        loss_test, acc_test = sess.run(\n",
    "                [loss, accuracy],\n",
    "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch})\n",
    "        loss_tests.append(loss_test)\n",
    "        pred.append(y_pred)\n",
    "        acc_tests.append(acc_test)\n",
    "        print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                  iteration, n_iterations_test,\n",
    "                  iteration * 100 / n_iterations_test),\n",
    "              end=\" \" * 10)\n",
    "    loss_test = np.mean(loss_tests)\n",
    "    #print(tf.confusion_matrix())\n",
    "    acc_test = np.mean(acc_tests)\n",
    "    print(\"\\rFinal test accuracy: {:.4f}%  Loss: {:.6f}\".format(\n",
    "        acc_test * 100, loss_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network3\n",
      "\n",
      "Accuracy is :  1.0\n",
      "\n",
      "AUROC is :  1.0\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[5638    0]\n",
      " [   0  321]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      5638\n",
      "        1.0       1.00      1.00      1.00       321\n",
      "\n",
      "avg / total       1.00      1.00      1.00      5959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: X_train.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "Y_train = Y_train.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score,accuracy_score\n",
    "print(\"\")\n",
    "print(\"Accuracy is : \", accuracy_score(Y_train,pred))\n",
    "print(\"\")\n",
    "print(\"AUROC is : \", roc_auc_score(Y_train,pred))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(Y_train, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(Y_train, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network3\n",
      "\n",
      "Accuracy is :  0.9873015873015873\n",
      "\n",
      "AUROC is :  0.9760737922150989\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[491   2]\n",
      " [  6 131]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99       493\n",
      "        1.0       0.98      0.96      0.97       137\n",
      "\n",
      "avg / total       0.99      0.99      0.99       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: valX.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "valY = valY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score,accuracy_score\n",
    "print(\"\")\n",
    "print(\"Accuracy is : \", accuracy_score(valY,pred))\n",
    "print(\"\")\n",
    "print(\"AUROC is : \", roc_auc_score(valY,pred))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(valY, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(valY, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network3\n",
      "\n",
      "Accuracy is :  0.99128160418483\n",
      "\n",
      "AUROC is :  0.9635036496350364\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[1010    0]\n",
      " [  10  127]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      1010\n",
      "        1.0       1.00      0.93      0.96       137\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: testX.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "testY = testY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score,accuracy_score\n",
    "print(\"\")\n",
    "print(\"Accuracy is : \", accuracy_score(testY,pred))\n",
    "print(\"\")\n",
    "print(\"AUROC is : \", roc_auc_score(testY,pred))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(testY, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(testY, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network3\n",
      "AUROC is :  0.9993495699934956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./my_capsule_network3\"\n",
    "with tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    prob = sess.run(\n",
    "            [y_proba],\n",
    "            feed_dict={X: testX.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "prob = np.array(prob)\n",
    "probs = np.array(prob[0,:,0,1,0])\n",
    "probs = probs.flatten()\n",
    "testY = testY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score,accuracy_score\n",
    "print(\"AUROC is : \", roc_auc_score(testY,probs))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
