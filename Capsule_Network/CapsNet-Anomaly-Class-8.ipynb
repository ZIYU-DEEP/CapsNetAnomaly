{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inderjeet78/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-4141630e56b4>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/inderjeet78/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/inderjeet78/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/inderjeet78/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/inderjeet78/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5389, 785)\n",
      "(49611, 785)\n",
      "[[0. 0. 0. ... 0. 0. 7.]\n",
      " [0. 0. 0. ... 0. 0. 3.]\n",
      " [0. 0. 0. ... 0. 0. 4.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 3.]\n",
      " [0. 0. 0. ... 0. 0. 5.]\n",
      " [0. 0. 0. ... 0. 0. 6.]]\n",
      "(49611, 785)\n",
      "(321, 785)\n"
     ]
    }
   ],
   "source": [
    "c1_x = mnist.train.images[mnist.train.labels==8]\n",
    "c1_y = mnist.train.labels[mnist.train.labels==8]\n",
    "c1_y = c1_y[:,None]\n",
    "other_x = mnist.train.images[mnist.train.labels!=8]\n",
    "other_y = mnist.train.labels[mnist.train.labels!=8]\n",
    "other_y=other_y[:,None]\n",
    "\n",
    "np.random.seed(42)\n",
    "c1 = np.concatenate((c1_x,c1_y),axis=1)\n",
    "others = np.concatenate((other_x,other_y), axis=1)\n",
    "print(c1.shape)\n",
    "print(others.shape)\n",
    "print(others)\n",
    "np.random.shuffle(others)\n",
    "others = np.array(others)\n",
    "print(others.shape)\n",
    "others321 = others[0:321,:]\n",
    "print(others321.shape)\n",
    "train = np.concatenate((c1,others321),axis=0)\n",
    "np.random.shuffle(train)\n",
    "X_train = train[:,0:-1]\n",
    "Y_train = train[:,-1]\n",
    "Y_train[Y_train==0]=1\n",
    "Y_train[Y_train==8]=0\n",
    "Y_train[Y_train!=0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "valX_ones = mnist.validation.images[mnist.validation.labels==8]\n",
    "valY_ones = mnist.validation.labels[mnist.validation.labels==8]\n",
    "valX_others = mnist.validation.images[mnist.validation.labels!=8]\n",
    "valY_others = mnist.validation.labels[mnist.validation.labels!=8]\n",
    "valY_ones = valY_ones[:,None]\n",
    "valY_others = valY_others[:,None]\n",
    "val_ones = np.concatenate((valX_ones,valY_ones),axis=1)\n",
    "val_others = np.concatenate((valX_others,valY_others),axis=1)\n",
    "np.random.shuffle(val_others)\n",
    "val_others137 = val_others[0:137,:]\n",
    "val = np.concatenate((val_ones,val_others137),axis=0)\n",
    "np.random.shuffle(val)\n",
    "valX = val[:,0:-1]\n",
    "valY = val[:,-1]\n",
    "valY[valY==0]=1\n",
    "valY[valY==8]=0\n",
    "valY[valY!=0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(valY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "testX_ones = mnist.test.images[mnist.test.labels==8]\n",
    "testY_ones = mnist.test.labels[mnist.test.labels==8]\n",
    "testX_others = mnist.test.images[mnist.test.labels!=8]\n",
    "testY_others = mnist.test.labels[mnist.test.labels!=8]\n",
    "testY_ones = testY_ones[:,None]\n",
    "testY_others = testY_others[:,None]\n",
    "test_ones = np.concatenate((testX_ones,testY_ones),axis=1)\n",
    "test_others = np.concatenate((testX_others,testY_others),axis=1)\n",
    "np.random.shuffle(test_others)\n",
    "test_others137 = test_others[0:137,:]\n",
    "test = np.concatenate((test_ones,test_others137),axis=0)\n",
    "np.random.shuffle(test)\n",
    "testX = test[:,0:-1]\n",
    "testY = test[:,-1]\n",
    "testY[testY==0]=1\n",
    "testY[testY==8]=0\n",
    "testY[testY!=0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3600x216 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 25\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(14,n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    sample_image = X_train[index].reshape(28, 28)\n",
    "    plt.imshow(sample_image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:n_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-d9e33cb66a21>:32: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From <ipython-input-11-d9e33cb66a21>:67: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32, name=\"X\")\n",
    "\n",
    "caps1_n_maps = 32\n",
    "caps1_n_caps = caps1_n_maps * 6 * 6  # 1152 primary capsules\n",
    "caps1_n_dims = 8\n",
    "\n",
    "conv1_params = {\n",
    "    \"filters\": 256,\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 1,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu,\n",
    "}\n",
    "\n",
    "conv2_params = {\n",
    "    \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 2,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\n",
    "\n",
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
    "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)\n",
    "\n",
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                       name=\"caps1_raw\")\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector\n",
    "\n",
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")\n",
    "\n",
    "caps2_n_caps = 2\n",
    "caps2_n_dims = 16\n",
    "\n",
    "init_sigma = 0.1\n",
    "\n",
    "W_init = tf.random_normal(\n",
    "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "W = tf.Variable(W_init, name=\"W\")\n",
    "\n",
    "batch_size = tf.shape(X)[0]\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")\n",
    "\n",
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                       name=\"caps1_output_expanded\")\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                   name=\"caps1_output_tile\")\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                             name=\"caps1_output_tiled\")\n",
    "\n",
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
    "                            name=\"caps2_predicted\")\n",
    "\n",
    "# Dynamic Routing algorithm\n",
    "# Round 1\n",
    "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
    "                       dtype=np.float32, name=\"raw_weights\")\n",
    "routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")\n",
    "\n",
    "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
    "                                   name=\"weighted_predictions\")\n",
    "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
    "                             name=\"weighted_sum\")\n",
    "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
    "                              name=\"caps2_output_round_1\")\n",
    "\n",
    "caps2_output_round_1_tiled = tf.tile(\n",
    "    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_1_tiled\")\n",
    "\n",
    "agreement1 = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
    "                      transpose_a=True, name=\"agreement1\")\n",
    "# Round 2\n",
    "# Routing weight update\n",
    "raw_weights_round_2 = tf.add(raw_weights, agreement1,\n",
    "                             name=\"raw_weights_round_2\")\n",
    "routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_2\")\n",
    "weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_2\")\n",
    "weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_2\")\n",
    "caps2_output_round_2 = squash(weighted_sum_round_2,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_2\")\n",
    "caps2_output_round_2_tiled = tf.tile(\n",
    "    caps2_output_round_2, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_2_tiled\")\n",
    "\n",
    "agreement2 = tf.matmul(caps2_predicted, caps2_output_round_2_tiled,\n",
    "                      transpose_a=True, name=\"agreement2\")\n",
    "\n",
    "# Round 3\n",
    "# Routing weight update\n",
    "raw_weights_round_3 = tf.add(raw_weights_round_2, agreement2,\n",
    "                             name=\"raw_weights_round_3\")\n",
    "routing_weights_round_3 = tf.nn.softmax(raw_weights_round_3,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_3\")\n",
    "weighted_predictions_round_3 = tf.multiply(routing_weights_round_3,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_3\")\n",
    "weighted_sum_round_3 = tf.reduce_sum(weighted_predictions_round_3,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_3\")\n",
    "caps2_output_round_3 = squash(weighted_sum_round_3,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_3\")\n",
    "caps2_output_round_3_tiled = tf.tile(\n",
    "    caps2_output_round_3, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_3_tiled\")\n",
    "\n",
    "agreement3 = tf.matmul(caps2_predicted, caps2_output_round_3_tiled,\n",
    "                      transpose_a=True, name=\"agreement3\")\n",
    "\n",
    "# Round 4\n",
    "# Routing weight update\n",
    "raw_weights_round_4 = tf.add(raw_weights_round_3, agreement3,\n",
    "                             name=\"raw_weights_round_4\")\n",
    "routing_weights_round_4 = tf.nn.softmax(raw_weights_round_4,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_4\")\n",
    "weighted_predictions_round_4 = tf.multiply(routing_weights_round_4,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_4\")\n",
    "weighted_sum_round_4 = tf.reduce_sum(weighted_predictions_round_4,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_4\")\n",
    "caps2_output_round_4 = squash(weighted_sum_round_4,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_4\")\n",
    "\"\"\"caps2_output_round_4_tiled = tf.tile(\n",
    "    caps2_output_round_4, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_4_tiled\")\n",
    "\n",
    "agreement4 = tf.matmul(caps2_predicted, caps2_output_round_4_tiled,\n",
    "                      transpose_a=True, name=\"agreement3\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "caps2_output = caps2_output_round_4\n",
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)\n",
    "\n",
    "y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")\n",
    "\n",
    "\n",
    "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n",
    "\n",
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
    "\n",
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")\n",
    "\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5\n",
    "\n",
    "T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")\n",
    "\n",
    "caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
    "                              name=\"caps2_output_norm\")\n",
    "\n",
    "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
    "                              name=\"present_error_raw\")\n",
    "present_error = tf.reshape(present_error_raw, shape=(-1, 2),\n",
    "                           name=\"present_error\")\n",
    "present_error\n",
    "\n",
    "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
    "                             name=\"absent_error_raw\")\n",
    "absent_error = tf.reshape(absent_error_raw, shape=(-1, 2),\n",
    "                          name=\"absent_error\")\n",
    "\n",
    "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
    "           name=\"L\")\n",
    "\n",
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n",
    "\n",
    "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
    "                                               name=\"mask_with_labels\")\n",
    "\n",
    "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                                 lambda: y,        # if True\n",
    "                                 lambda: y_pred,   # if False\n",
    "                                 name=\"reconstruction_targets\")\n",
    "\n",
    "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
    "                                 depth=caps2_n_caps,\n",
    "                                 name=\"reconstruction_mask\")\n",
    "\n",
    "reconstruction_mask_reshaped = tf.reshape(\n",
    "    reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],\n",
    "    name=\"reconstruction_mask_reshaped\")\n",
    "\n",
    "caps2_output_masked = tf.multiply(\n",
    "    caps2_output, reconstruction_mask_reshaped,\n",
    "    name=\"caps2_output_masked\")\n",
    "\n",
    "decoder_input = tf.reshape(caps2_output_masked,\n",
    "                           [-1, caps2_n_caps * caps2_n_dims],\n",
    "                           name=\"decoder_input\")\n",
    "\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 1024\n",
    "n_output = 28 * 28\n",
    "\n",
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
    "                                     activation=tf.nn.sigmoid,\n",
    "                                     name=\"decoder_output\")\n",
    "\n",
    "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "squared_difference = tf.square(X_flat - decoder_output,\n",
    "                               name=\"squared_difference\")\n",
    "reconstruction_loss = tf.reduce_mean(squared_difference,\n",
    "                                    name=\"reconstruction_loss\")\n",
    "\n",
    "alpha = 0.0005\n",
    "\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")\n",
    "\n",
    "\n",
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Val accuracy: 90.5454%  Loss: 0.049219 (improved)\n",
      "Epoch: 2  Val accuracy: 98.0000%  Loss: 0.022706 (improved)\n",
      "Epoch: 3  Val accuracy: 98.1818%  Loss: 0.019263 (improved)\n",
      "Epoch: 4  Val accuracy: 98.0000%  Loss: 0.018146 (improved)\n",
      "Epoch: 5  Val accuracy: 97.6364%  Loss: 0.020792\n",
      "Epoch: 6  Val accuracy: 98.3636%  Loss: 0.016579 (improved)\n",
      "Epoch: 7  Val accuracy: 98.1818%  Loss: 0.016902\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 7\n",
    "batch_size = 50\n",
    "restore_checkpoint = False\n",
    "n_iterations_per_epoch = len(X_train) // batch_size\n",
    "n_iterations_validation = len(valX) // batch_size\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network8\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            X_batch = X_train[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "            y_batch = Y_train[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "            # Run the training operation and measure the loss:\n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch,\n",
    "                           mask_with_labels: True})\n",
    "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                      iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "\n",
    "        # At the end of each epoch,  \n",
    "        # measure the validation loss and accuracy:\n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        for iteration in range(1, n_iterations_validation + 1):\n",
    "            X_batch = valX[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "            y_batch = valY[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "            loss_val, acc_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                               y: y_batch})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "        # And save the model if it improved: \n",
    "        \n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network8\n",
      "Final test accuracy: 98.6363%  Loss: 0.010160 \n"
     ]
    }
   ],
   "source": [
    "n_iterations_test = len(testX) // batch_size\n",
    "checkpoint_path = \"./my_capsule_network8\"\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    pred = []\n",
    "    loss_tests = []\n",
    "    acc_tests = []\n",
    "    for iteration in range(1, n_iterations_test + 1):\n",
    "        X_batch = testX[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "        y_batch = testY[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "        loss_test, acc_test = sess.run(\n",
    "                [loss, accuracy],\n",
    "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch})\n",
    "        loss_tests.append(loss_test)\n",
    "        pred.append(y_pred)\n",
    "        acc_tests.append(acc_test)\n",
    "        print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                  iteration, n_iterations_test,\n",
    "                  iteration * 100 / n_iterations_test),\n",
    "              end=\" \" * 10)\n",
    "    loss_test = np.mean(loss_tests)\n",
    "    #print(tf.confusion_matrix())\n",
    "    acc_test = np.mean(acc_tests)\n",
    "    print(\"\\rFinal test accuracy: {:.4f}%  Loss: {:.6f}\".format(\n",
    "        acc_test * 100, loss_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network8\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[5389    0]\n",
      " [   0  321]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      5389\n",
      "        1.0       1.00      1.00      1.00       321\n",
      "\n",
      "avg / total       1.00      1.00      1.00      5710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: X_train.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "Y_train = Y_train.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(Y_train, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(Y_train, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network8\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[462   0]\n",
      " [ 10 127]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99       462\n",
      "        1.0       1.00      0.93      0.96       137\n",
      "\n",
      "avg / total       0.98      0.98      0.98       599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: valX.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "valY = valY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(valY, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(valY, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network8\n",
      "\n",
      "Accuracy is :  0.9864986498649865\n",
      "\n",
      "AUROC is :  0.9452554744525548\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[974   0]\n",
      " [ 15 122]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99       974\n",
      "        1.0       1.00      0.89      0.94       137\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: testX.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "testY = testY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score,accuracy_score\n",
    "print(\"\")\n",
    "print(\"Accuracy is : \", accuracy_score(testY,pred))\n",
    "print(\"\")\n",
    "print(\"AUROC is : \", roc_auc_score(testY,pred))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(testY, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(testY, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network8\n",
      "AUROC is :  0.9955110238462807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    prob = sess.run(\n",
    "            [y_proba],\n",
    "            feed_dict={X: testX.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "prob = np.array(prob)\n",
    "probs = np.array(prob[0,:,0,1,0])\n",
    "probs = probs.flatten()\n",
    "testY = testY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score,accuracy_score\n",
    "print(\"AUROC is : \", roc_auc_score(testY,probs))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
