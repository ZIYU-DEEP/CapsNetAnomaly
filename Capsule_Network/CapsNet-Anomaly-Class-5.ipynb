{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4987, 785)\n",
      "(50013, 785)\n",
      "[[0. 0. 0. ... 0. 0. 7.]\n",
      " [0. 0. 0. ... 0. 0. 3.]\n",
      " [0. 0. 0. ... 0. 0. 4.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 3.]\n",
      " [0. 0. 0. ... 0. 0. 6.]\n",
      " [0. 0. 0. ... 0. 0. 8.]]\n",
      "(50013, 785)\n",
      "(321, 785)\n"
     ]
    }
   ],
   "source": [
    "c1_x = mnist.train.images[mnist.train.labels==5]\n",
    "c1_y = mnist.train.labels[mnist.train.labels==5]\n",
    "c1_y = c1_y[:,None]\n",
    "other_x = mnist.train.images[mnist.train.labels!=5]\n",
    "other_y = mnist.train.labels[mnist.train.labels!=5]\n",
    "other_y=other_y[:,None]\n",
    "\n",
    "np.random.seed(42)\n",
    "c1 = np.concatenate((c1_x,c1_y),axis=1)\n",
    "others = np.concatenate((other_x,other_y), axis=1)\n",
    "print(c1.shape)\n",
    "print(others.shape)\n",
    "print(others)\n",
    "np.random.shuffle(others)\n",
    "others = np.array(others)\n",
    "print(others.shape)\n",
    "others321 = others[0:321,:]\n",
    "print(others321.shape)\n",
    "train = np.concatenate((c1,others321),axis=0)\n",
    "np.random.shuffle(train)\n",
    "X_train = train[:,0:-1]\n",
    "Y_train = train[:,-1]\n",
    "Y_train[Y_train==0]=1\n",
    "Y_train[Y_train==5]=0\n",
    "Y_train[Y_train!=0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "valX_ones = mnist.validation.images[mnist.validation.labels==5]\n",
    "valY_ones = mnist.validation.labels[mnist.validation.labels==5]\n",
    "valX_others = mnist.validation.images[mnist.validation.labels!=5]\n",
    "valY_others = mnist.validation.labels[mnist.validation.labels!=5]\n",
    "valY_ones = valY_ones[:,None]\n",
    "valY_others = valY_others[:,None]\n",
    "val_ones = np.concatenate((valX_ones,valY_ones),axis=1)\n",
    "val_others = np.concatenate((valX_others,valY_others),axis=1)\n",
    "np.random.shuffle(val_others)\n",
    "val_others137 = val_others[0:137,:]\n",
    "val = np.concatenate((val_ones,val_others137),axis=0)\n",
    "np.random.shuffle(val)\n",
    "valX = val[:,0:-1]\n",
    "valY = val[:,-1]\n",
    "valY[valY==0]=1\n",
    "valY[valY==5]=0\n",
    "valY[valY!=0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(valY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "testX_ones = mnist.test.images[mnist.test.labels==5]\n",
    "testY_ones = mnist.test.labels[mnist.test.labels==5]\n",
    "testX_others = mnist.test.images[mnist.test.labels!=5]\n",
    "testY_others = mnist.test.labels[mnist.test.labels!=5]\n",
    "testY_ones = testY_ones[:,None]\n",
    "testY_others = testY_others[:,None]\n",
    "test_ones = np.concatenate((testX_ones,testY_ones),axis=1)\n",
    "test_others = np.concatenate((testX_others,testY_others),axis=1)\n",
    "np.random.shuffle(test_others)\n",
    "test_others137 = test_others[0:137,:]\n",
    "test = np.concatenate((test_ones,test_others137),axis=0)\n",
    "np.random.shuffle(test)\n",
    "testX = test[:,0:-1]\n",
    "testY = test[:,-1]\n",
    "testY[testY==0]=1\n",
    "testY[testY==5]=0\n",
    "testY[testY!=0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3600x216 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 25\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(14,n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    sample_image = X_train[index].reshape(28, 28)\n",
    "    plt.imshow(sample_image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:n_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32, name=\"X\")\n",
    "\n",
    "caps1_n_maps = 32\n",
    "caps1_n_caps = caps1_n_maps * 6 * 6  # 1152 primary capsules\n",
    "caps1_n_dims = 8\n",
    "\n",
    "conv1_params = {\n",
    "    \"filters\": 256,\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 1,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu,\n",
    "}\n",
    "\n",
    "conv2_params = {\n",
    "    \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 2,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\n",
    "\n",
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
    "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)\n",
    "\n",
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                       name=\"caps1_raw\")\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector\n",
    "\n",
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")\n",
    "\n",
    "caps2_n_caps = 2\n",
    "caps2_n_dims = 16\n",
    "\n",
    "init_sigma = 0.1\n",
    "\n",
    "W_init = tf.random_normal(\n",
    "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "W = tf.Variable(W_init, name=\"W\")\n",
    "\n",
    "batch_size = tf.shape(X)[0]\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")\n",
    "\n",
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                       name=\"caps1_output_expanded\")\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                   name=\"caps1_output_tile\")\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                             name=\"caps1_output_tiled\")\n",
    "\n",
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
    "                            name=\"caps2_predicted\")\n",
    "\n",
    "# Dynamic Routing algorithm\n",
    "# Round 1\n",
    "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
    "                       dtype=np.float32, name=\"raw_weights\")\n",
    "routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")\n",
    "\n",
    "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
    "                                   name=\"weighted_predictions\")\n",
    "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
    "                             name=\"weighted_sum\")\n",
    "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
    "                              name=\"caps2_output_round_1\")\n",
    "\n",
    "caps2_output_round_1_tiled = tf.tile(\n",
    "    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_1_tiled\")\n",
    "\n",
    "agreement1 = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
    "                      transpose_a=True, name=\"agreement1\")\n",
    "# Round 2\n",
    "# Routing weight update\n",
    "raw_weights_round_2 = tf.add(raw_weights, agreement1,\n",
    "                             name=\"raw_weights_round_2\")\n",
    "routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_2\")\n",
    "weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_2\")\n",
    "weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_2\")\n",
    "caps2_output_round_2 = squash(weighted_sum_round_2,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_2\")\n",
    "caps2_output_round_2_tiled = tf.tile(\n",
    "    caps2_output_round_2, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_2_tiled\")\n",
    "\n",
    "agreement2 = tf.matmul(caps2_predicted, caps2_output_round_2_tiled,\n",
    "                      transpose_a=True, name=\"agreement2\")\n",
    "\n",
    "# Round 3\n",
    "# Routing weight update\n",
    "raw_weights_round_3 = tf.add(raw_weights_round_2, agreement2,\n",
    "                             name=\"raw_weights_round_3\")\n",
    "routing_weights_round_3 = tf.nn.softmax(raw_weights_round_3,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_3\")\n",
    "weighted_predictions_round_3 = tf.multiply(routing_weights_round_3,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_3\")\n",
    "weighted_sum_round_3 = tf.reduce_sum(weighted_predictions_round_3,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_3\")\n",
    "caps2_output_round_3 = squash(weighted_sum_round_3,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_3\")\n",
    "caps2_output_round_3_tiled = tf.tile(\n",
    "    caps2_output_round_3, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_3_tiled\")\n",
    "\n",
    "agreement3 = tf.matmul(caps2_predicted, caps2_output_round_3_tiled,\n",
    "                      transpose_a=True, name=\"agreement3\")\n",
    "\n",
    "# Round 4\n",
    "# Routing weight update\n",
    "raw_weights_round_4 = tf.add(raw_weights_round_3, agreement3,\n",
    "                             name=\"raw_weights_round_4\")\n",
    "routing_weights_round_4 = tf.nn.softmax(raw_weights_round_4,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_4\")\n",
    "weighted_predictions_round_4 = tf.multiply(routing_weights_round_4,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_4\")\n",
    "weighted_sum_round_4 = tf.reduce_sum(weighted_predictions_round_4,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_4\")\n",
    "caps2_output_round_4 = squash(weighted_sum_round_4,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_4\")\n",
    "\"\"\"caps2_output_round_4_tiled = tf.tile(\n",
    "    caps2_output_round_4, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_4_tiled\")\n",
    "\n",
    "agreement4 = tf.matmul(caps2_predicted, caps2_output_round_4_tiled,\n",
    "                      transpose_a=True, name=\"agreement3\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "caps2_output = caps2_output_round_4\n",
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)\n",
    "\n",
    "y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")\n",
    "\n",
    "\n",
    "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n",
    "\n",
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
    "\n",
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")\n",
    "\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5\n",
    "\n",
    "T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")\n",
    "\n",
    "caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
    "                              name=\"caps2_output_norm\")\n",
    "\n",
    "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
    "                              name=\"present_error_raw\")\n",
    "present_error = tf.reshape(present_error_raw, shape=(-1, 2),\n",
    "                           name=\"present_error\")\n",
    "present_error\n",
    "\n",
    "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
    "                             name=\"absent_error_raw\")\n",
    "absent_error = tf.reshape(absent_error_raw, shape=(-1, 2),\n",
    "                          name=\"absent_error\")\n",
    "\n",
    "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
    "           name=\"L\")\n",
    "\n",
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n",
    "\n",
    "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
    "                                               name=\"mask_with_labels\")\n",
    "\n",
    "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                                 lambda: y,        # if True\n",
    "                                 lambda: y_pred,   # if False\n",
    "                                 name=\"reconstruction_targets\")\n",
    "\n",
    "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
    "                                 depth=caps2_n_caps,\n",
    "                                 name=\"reconstruction_mask\")\n",
    "\n",
    "reconstruction_mask_reshaped = tf.reshape(\n",
    "    reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],\n",
    "    name=\"reconstruction_mask_reshaped\")\n",
    "\n",
    "caps2_output_masked = tf.multiply(\n",
    "    caps2_output, reconstruction_mask_reshaped,\n",
    "    name=\"caps2_output_masked\")\n",
    "\n",
    "decoder_input = tf.reshape(caps2_output_masked,\n",
    "                           [-1, caps2_n_caps * caps2_n_dims],\n",
    "                           name=\"decoder_input\")\n",
    "\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 1024\n",
    "n_output = 28 * 28\n",
    "\n",
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
    "                                     activation=tf.nn.sigmoid,\n",
    "                                     name=\"decoder_output\")\n",
    "\n",
    "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "squared_difference = tf.square(X_flat - decoder_output,\n",
    "                               name=\"squared_difference\")\n",
    "reconstruction_loss = tf.reduce_mean(squared_difference,\n",
    "                                    name=\"reconstruction_loss\")\n",
    "\n",
    "alpha = 0.0005\n",
    "\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")\n",
    "\n",
    "\n",
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Val accuracy: 75.6364%  Loss: 0.095105 (improved)\n",
      "Epoch: 2  Val accuracy: 98.5455%  Loss: 0.014744 (improved)\n",
      "Epoch: 3  Val accuracy: 98.5455%  Loss: 0.015423\n",
      "Epoch: 4  Val accuracy: 97.8182%  Loss: 0.019574\n",
      "Epoch: 5  Val accuracy: 97.6364%  Loss: 0.015486\n",
      "Epoch: 6  Val accuracy: 98.5454%  Loss: 0.010613 (improved)\n",
      "Epoch: 7  Val accuracy: 98.9091%  Loss: 0.008741 (improved)\n",
      "Epoch: 8  Val accuracy: 99.2727%  Loss: 0.007305 (improved)\n",
      "Epoch: 9  Val accuracy: 99.0909%  Loss: 0.008341\n",
      "Epoch: 10  Val accuracy: 99.2727%  Loss: 0.007306\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 50\n",
    "restore_checkpoint = False\n",
    "n_iterations_per_epoch = len(X_train) // batch_size\n",
    "n_iterations_validation = len(valX) // batch_size\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network5\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            X_batch = X_train[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "            y_batch = Y_train[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "            # Run the training operation and measure the loss:\n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch,\n",
    "                           mask_with_labels: True})\n",
    "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                      iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "\n",
    "        # At the end of each epoch,  \n",
    "        # measure the validation loss and accuracy:\n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        for iteration in range(1, n_iterations_validation + 1):\n",
    "            X_batch = valX[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "            y_batch = valY[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "            loss_val, acc_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                               y: y_batch})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "        # And save the model if it improved: \n",
    "        \n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network5\n",
      "Final test accuracy: 99.3000%  Loss: 0.006555 \n"
     ]
    }
   ],
   "source": [
    "n_iterations_test = len(testX) // batch_size\n",
    "checkpoint_path = \"./my_capsule_network5\"\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    pred = []\n",
    "    loss_tests = []\n",
    "    acc_tests = []\n",
    "    for iteration in range(1, n_iterations_test + 1):\n",
    "        X_batch = testX[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "        y_batch = testY[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "        loss_test, acc_test = sess.run(\n",
    "                [loss, accuracy],\n",
    "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch})\n",
    "        loss_tests.append(loss_test)\n",
    "        pred.append(y_pred)\n",
    "        acc_tests.append(acc_test)\n",
    "        print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                  iteration, n_iterations_test,\n",
    "                  iteration * 100 / n_iterations_test),\n",
    "              end=\" \" * 10)\n",
    "    loss_test = np.mean(loss_tests)\n",
    "    #print(tf.confusion_matrix())\n",
    "    acc_test = np.mean(acc_tests)\n",
    "    print(\"\\rFinal test accuracy: {:.4f}%  Loss: {:.6f}\".format(\n",
    "        acc_test * 100, loss_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network5\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[4987    0]\n",
      " [   0  321]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      4987\n",
      "        1.0       1.00      1.00      1.00       321\n",
      "\n",
      "avg / total       1.00      1.00      1.00      5308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: X_train.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "Y_train = Y_train.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(Y_train, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(Y_train, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network5\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[433   1]\n",
      " [  3 134]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00       434\n",
      "        1.0       0.99      0.98      0.99       137\n",
      "\n",
      "avg / total       0.99      0.99      0.99       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: valX.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "valY = valY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(valY, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(valY, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network5\n",
      "\n",
      "Accuracy is :  0.9931972789115646\n",
      "\n",
      "AUROC is :  0.9775416516644301\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[891   1]\n",
      " [  6 131]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00       892\n",
      "        1.0       0.99      0.96      0.97       137\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: testX.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "testY = testY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score,accuracy_score\n",
    "print(\"\")\n",
    "print(\"Accuracy is : \", accuracy_score(testY,pred))\n",
    "print(\"\")\n",
    "print(\"AUROC is : \", roc_auc_score(testY,pred))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(testY, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(testY, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network5\n",
      "AUROC is :  0.9995253837844915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./my_capsule_network5\"\n",
    "with tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    prob = sess.run(\n",
    "            [y_proba],\n",
    "            feed_dict={X: testX.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "prob = np.array(prob)\n",
    "probs = np.array(prob[0,:,0,1,0])\n",
    "probs = probs.flatten()\n",
    "testY = testY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score,accuracy_score\n",
    "print(\"AUROC is : \", roc_auc_score(testY,probs))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
