{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5307, 785)\n",
      "(49693, 785)\n",
      "[[0. 0. 0. ... 0. 0. 7.]\n",
      " [0. 0. 0. ... 0. 0. 3.]\n",
      " [0. 0. 0. ... 0. 0. 6.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 5.]\n",
      " [0. 0. 0. ... 0. 0. 6.]\n",
      " [0. 0. 0. ... 0. 0. 8.]]\n",
      "(49693, 785)\n",
      "(321, 785)\n"
     ]
    }
   ],
   "source": [
    "c1_x = mnist.train.images[mnist.train.labels==4]\n",
    "c1_y = mnist.train.labels[mnist.train.labels==4]\n",
    "c1_y = c1_y[:,None]\n",
    "other_x = mnist.train.images[mnist.train.labels!=4]\n",
    "other_y = mnist.train.labels[mnist.train.labels!=4]\n",
    "other_y=other_y[:,None]\n",
    "\n",
    "np.random.seed(42)\n",
    "c1 = np.concatenate((c1_x,c1_y),axis=1)\n",
    "others = np.concatenate((other_x,other_y), axis=1)\n",
    "print(c1.shape)\n",
    "print(others.shape)\n",
    "print(others)\n",
    "np.random.shuffle(others)\n",
    "others = np.array(others)\n",
    "print(others.shape)\n",
    "others321 = others[0:321,:]\n",
    "print(others321.shape)\n",
    "train = np.concatenate((c1,others321),axis=0)\n",
    "np.random.shuffle(train)\n",
    "X_train = train[:,0:-1]\n",
    "Y_train = train[:,-1]\n",
    "Y_train[Y_train==0]=1\n",
    "Y_train[Y_train==4]=0\n",
    "Y_train[Y_train!=0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "valX_ones = mnist.validation.images[mnist.validation.labels==4]\n",
    "valY_ones = mnist.validation.labels[mnist.validation.labels==4]\n",
    "valX_others = mnist.validation.images[mnist.validation.labels!=4]\n",
    "valY_others = mnist.validation.labels[mnist.validation.labels!=4]\n",
    "valY_ones = valY_ones[:,None]\n",
    "valY_others = valY_others[:,None]\n",
    "val_ones = np.concatenate((valX_ones,valY_ones),axis=1)\n",
    "val_others = np.concatenate((valX_others,valY_others),axis=1)\n",
    "np.random.shuffle(val_others)\n",
    "val_others137 = val_others[0:137,:]\n",
    "val = np.concatenate((val_ones,val_others137),axis=0)\n",
    "np.random.shuffle(val)\n",
    "valX = val[:,0:-1]\n",
    "valY = val[:,-1]\n",
    "valY[valY==0]=1\n",
    "valY[valY==4]=0\n",
    "valY[valY!=0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(valY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "testX_ones = mnist.test.images[mnist.test.labels==4]\n",
    "testY_ones = mnist.test.labels[mnist.test.labels==4]\n",
    "testX_others = mnist.test.images[mnist.test.labels!=4]\n",
    "testY_others = mnist.test.labels[mnist.test.labels!=4]\n",
    "testY_ones = testY_ones[:,None]\n",
    "testY_others = testY_others[:,None]\n",
    "test_ones = np.concatenate((testX_ones,testY_ones),axis=1)\n",
    "test_others = np.concatenate((testX_others,testY_others),axis=1)\n",
    "np.random.shuffle(test_others)\n",
    "test_others137 = test_others[0:137,:]\n",
    "test = np.concatenate((test_ones,test_others137),axis=0)\n",
    "np.random.shuffle(test)\n",
    "testX = test[:,0:-1]\n",
    "testY = test[:,-1]\n",
    "testY[testY==0]=1\n",
    "testY[testY==4]=0\n",
    "testY[testY!=0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3600x216 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 25\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(14,n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    sample_image = X_train[index].reshape(28, 28)\n",
    "    plt.imshow(sample_image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:n_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32, name=\"X\")\n",
    "\n",
    "caps1_n_maps = 32\n",
    "caps1_n_caps = caps1_n_maps * 6 * 6  # 1152 primary capsules\n",
    "caps1_n_dims = 8\n",
    "\n",
    "conv1_params = {\n",
    "    \"filters\": 256,\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 1,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu,\n",
    "}\n",
    "\n",
    "conv2_params = {\n",
    "    \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 2,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\n",
    "\n",
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
    "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)\n",
    "\n",
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                       name=\"caps1_raw\")\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector\n",
    "\n",
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")\n",
    "\n",
    "caps2_n_caps = 2\n",
    "caps2_n_dims = 16\n",
    "\n",
    "init_sigma = 0.1\n",
    "\n",
    "W_init = tf.random_normal(\n",
    "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "W = tf.Variable(W_init, name=\"W\")\n",
    "\n",
    "batch_size = tf.shape(X)[0]\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")\n",
    "\n",
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                       name=\"caps1_output_expanded\")\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                   name=\"caps1_output_tile\")\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                             name=\"caps1_output_tiled\")\n",
    "\n",
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
    "                            name=\"caps2_predicted\")\n",
    "\n",
    "# Dynamic Routing algorithm\n",
    "# Round 1\n",
    "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
    "                       dtype=np.float32, name=\"raw_weights\")\n",
    "routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")\n",
    "\n",
    "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
    "                                   name=\"weighted_predictions\")\n",
    "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
    "                             name=\"weighted_sum\")\n",
    "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
    "                              name=\"caps2_output_round_1\")\n",
    "\n",
    "caps2_output_round_1_tiled = tf.tile(\n",
    "    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_1_tiled\")\n",
    "\n",
    "agreement1 = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
    "                      transpose_a=True, name=\"agreement1\")\n",
    "# Round 2\n",
    "# Routing weight update\n",
    "raw_weights_round_2 = tf.add(raw_weights, agreement1,\n",
    "                             name=\"raw_weights_round_2\")\n",
    "routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_2\")\n",
    "weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_2\")\n",
    "weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_2\")\n",
    "caps2_output_round_2 = squash(weighted_sum_round_2,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_2\")\n",
    "caps2_output_round_2_tiled = tf.tile(\n",
    "    caps2_output_round_2, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_2_tiled\")\n",
    "\n",
    "agreement2 = tf.matmul(caps2_predicted, caps2_output_round_2_tiled,\n",
    "                      transpose_a=True, name=\"agreement2\")\n",
    "\n",
    "# Round 3\n",
    "# Routing weight update\n",
    "raw_weights_round_3 = tf.add(raw_weights_round_2, agreement2,\n",
    "                             name=\"raw_weights_round_3\")\n",
    "routing_weights_round_3 = tf.nn.softmax(raw_weights_round_3,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_3\")\n",
    "weighted_predictions_round_3 = tf.multiply(routing_weights_round_3,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_3\")\n",
    "weighted_sum_round_3 = tf.reduce_sum(weighted_predictions_round_3,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_3\")\n",
    "caps2_output_round_3 = squash(weighted_sum_round_3,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_3\")\n",
    "caps2_output_round_3_tiled = tf.tile(\n",
    "    caps2_output_round_3, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_3_tiled\")\n",
    "\n",
    "agreement3 = tf.matmul(caps2_predicted, caps2_output_round_3_tiled,\n",
    "                      transpose_a=True, name=\"agreement3\")\n",
    "\n",
    "# Round 4\n",
    "# Routing weight update\n",
    "raw_weights_round_4 = tf.add(raw_weights_round_3, agreement3,\n",
    "                             name=\"raw_weights_round_4\")\n",
    "routing_weights_round_4 = tf.nn.softmax(raw_weights_round_4,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_4\")\n",
    "weighted_predictions_round_4 = tf.multiply(routing_weights_round_4,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_4\")\n",
    "weighted_sum_round_4 = tf.reduce_sum(weighted_predictions_round_4,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_4\")\n",
    "caps2_output_round_4 = squash(weighted_sum_round_4,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_4\")\n",
    "\"\"\"caps2_output_round_4_tiled = tf.tile(\n",
    "    caps2_output_round_4, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_4_tiled\")\n",
    "\n",
    "agreement4 = tf.matmul(caps2_predicted, caps2_output_round_4_tiled,\n",
    "                      transpose_a=True, name=\"agreement3\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "caps2_output = caps2_output_round_4\n",
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)\n",
    "\n",
    "y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")\n",
    "\n",
    "\n",
    "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n",
    "\n",
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
    "\n",
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")\n",
    "\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5\n",
    "\n",
    "T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")\n",
    "\n",
    "caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
    "                              name=\"caps2_output_norm\")\n",
    "\n",
    "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
    "                              name=\"present_error_raw\")\n",
    "present_error = tf.reshape(present_error_raw, shape=(-1, 2),\n",
    "                           name=\"present_error\")\n",
    "present_error\n",
    "\n",
    "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
    "                             name=\"absent_error_raw\")\n",
    "absent_error = tf.reshape(absent_error_raw, shape=(-1, 2),\n",
    "                          name=\"absent_error\")\n",
    "\n",
    "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
    "           name=\"L\")\n",
    "\n",
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n",
    "\n",
    "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
    "                                               name=\"mask_with_labels\")\n",
    "\n",
    "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                                 lambda: y,        # if True\n",
    "                                 lambda: y_pred,   # if False\n",
    "                                 name=\"reconstruction_targets\")\n",
    "\n",
    "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
    "                                 depth=caps2_n_caps,\n",
    "                                 name=\"reconstruction_mask\")\n",
    "\n",
    "reconstruction_mask_reshaped = tf.reshape(\n",
    "    reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],\n",
    "    name=\"reconstruction_mask_reshaped\")\n",
    "\n",
    "caps2_output_masked = tf.multiply(\n",
    "    caps2_output, reconstruction_mask_reshaped,\n",
    "    name=\"caps2_output_masked\")\n",
    "\n",
    "decoder_input = tf.reshape(caps2_output_masked,\n",
    "                           [-1, caps2_n_caps * caps2_n_dims],\n",
    "                           name=\"decoder_input\")\n",
    "\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 1024\n",
    "n_output = 28 * 28\n",
    "\n",
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
    "                                     activation=tf.nn.sigmoid,\n",
    "                                     name=\"decoder_output\")\n",
    "\n",
    "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "squared_difference = tf.square(X_flat - decoder_output,\n",
    "                               name=\"squared_difference\")\n",
    "reconstruction_loss = tf.reduce_mean(squared_difference,\n",
    "                                    name=\"reconstruction_loss\")\n",
    "\n",
    "alpha = 0.0005\n",
    "\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")\n",
    "\n",
    "\n",
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Val accuracy: 95.2308%  Loss: 0.035206 (improved)\n",
      "Epoch: 2  Val accuracy: 96.3077%  Loss: 0.024181 (improved)\n",
      "Epoch: 3  Val accuracy: 97.6923%  Loss: 0.016026 (improved)\n",
      "Epoch: 4  Val accuracy: 98.9231%  Loss: 0.012195 (improved)\n",
      "Epoch: 5  Val accuracy: 98.9231%  Loss: 0.013253\n",
      "Epoch: 6  Val accuracy: 99.0769%  Loss: 0.009613 (improved)\n",
      "Epoch: 7  Val accuracy: 98.6154%  Loss: 0.014012\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 7\n",
    "batch_size = 50\n",
    "restore_checkpoint = False\n",
    "n_iterations_per_epoch = len(X_train) // batch_size\n",
    "n_iterations_validation = len(valX) // batch_size\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network4\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            X_batch = X_train[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "            y_batch = Y_train[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "            # Run the training operation and measure the loss:\n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch,\n",
    "                           mask_with_labels: True})\n",
    "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                      iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "\n",
    "        # At the end of each epoch,  \n",
    "        # measure the validation loss and accuracy:\n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        for iteration in range(1, n_iterations_validation + 1):\n",
    "            X_batch = valX[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "            y_batch = valY[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "            loss_val, acc_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                               y: y_batch})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "        # And save the model if it improved: \n",
    "        \n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network4\n",
      "Final test accuracy: 99.2727%  Loss: 0.006290 \n"
     ]
    }
   ],
   "source": [
    "n_iterations_test = len(testX) // batch_size\n",
    "checkpoint_path = \"./my_capsule_network4\"\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    pred = []\n",
    "    loss_tests = []\n",
    "    acc_tests = []\n",
    "    for iteration in range(1, n_iterations_test + 1):\n",
    "        X_batch = testX[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "        y_batch = testY[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "        loss_test, acc_test = sess.run(\n",
    "                [loss, accuracy],\n",
    "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch})\n",
    "        loss_tests.append(loss_test)\n",
    "        pred.append(y_pred)\n",
    "        acc_tests.append(acc_test)\n",
    "        print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                  iteration, n_iterations_test,\n",
    "                  iteration * 100 / n_iterations_test),\n",
    "              end=\" \" * 10)\n",
    "    loss_test = np.mean(loss_tests)\n",
    "    #print(tf.confusion_matrix())\n",
    "    acc_test = np.mean(acc_tests)\n",
    "    print(\"\\rFinal test accuracy: {:.4f}%  Loss: {:.6f}\".format(\n",
    "        acc_test * 100, loss_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network4\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[5305    2]\n",
      " [   0  321]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      5307\n",
      "        1.0       0.99      1.00      1.00       321\n",
      "\n",
      "avg / total       1.00      1.00      1.00      5628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: X_train.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "Y_train = Y_train.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(Y_train, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(Y_train, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network4\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[534   1]\n",
      " [  5 132]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99       535\n",
      "        1.0       0.99      0.96      0.98       137\n",
      "\n",
      "avg / total       0.99      0.99      0.99       672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: valX.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "valY = valY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(valY, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(valY, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network4\n",
      "\n",
      "Accuracy is :  0.9928507596067918\n",
      "\n",
      "AUROC is :  0.9708029197080292\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[982   0]\n",
      " [  8 129]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00       982\n",
      "        1.0       1.00      0.94      0.97       137\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: testX.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "testY = testY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score,accuracy_score\n",
    "print(\"\")\n",
    "print(\"Accuracy is : \", accuracy_score(testY,pred))\n",
    "print(\"\")\n",
    "print(\"AUROC is : \", roc_auc_score(testY,pred))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(testY, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(testY, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network4\n",
      "AUROC is :  0.99930129186674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./my_capsule_network4\"\n",
    "with tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    prob = sess.run(\n",
    "            [y_proba],\n",
    "            feed_dict={X: testX.reshape([-1, 28, 28, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "prob = np.array(prob)\n",
    "probs = np.array(prob[0,:,0,1,0])\n",
    "probs = probs.flatten()\n",
    "testY = testY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score,accuracy_score\n",
    "print(\"AUROC is : \", roc_auc_score(testY,probs))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
