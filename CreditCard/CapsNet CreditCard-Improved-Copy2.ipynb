{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inderjeet78/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.reset_default_graph()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time','Amount'],axis=1)\n",
    "X = data.iloc[:,data.columns != 'Class']\n",
    "Y = data.iloc[:,data.columns == 'Class']\n",
    "pca = PCA(n_components=25)\n",
    "X = pca.fit_transform(X)\n",
    "X_train,testX,Y_train,testY = train_test_split(X,Y,test_size=0.20,random_state=21, stratify=Y)\n",
    "X_train,valX,Y_train,valY = train_test_split(X_train,Y_train,test_size=0.20,random_state=21, stratify=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "valX = np.array(valX)\n",
    "testX = np.array(testX)\n",
    "Y_train = np.array(Y_train)\n",
    "valY = np.array(valY)\n",
    "testY = np.array(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-2bb56688f5ea>:32: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From <ipython-input-4-2bb56688f5ea>:67: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(shape=[None, 5, 5, 1], dtype=tf.float32, name=\"X\")\n",
    "\n",
    "caps1_n_maps = 8\n",
    "caps1_n_caps = caps1_n_maps * 4 * 4  # 1152 primary capsules\n",
    "caps1_n_dims = 4\n",
    "\n",
    "conv1_params = {\n",
    "    \"filters\": 32,\n",
    "    \"kernel_size\": 2,\n",
    "    \"strides\": 1,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu,\n",
    "}\n",
    "\n",
    "\"\"\"conv2_params = {\n",
    "    \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 2,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\"\"\"\n",
    "\n",
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
    "#conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)\n",
    "\n",
    "caps1_raw = tf.reshape(conv1, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                       name=\"caps1_raw\")\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector\n",
    "\n",
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")\n",
    "\n",
    "caps2_n_caps = 2\n",
    "caps2_n_dims = 6\n",
    "\n",
    "init_sigma = 0.1\n",
    "\n",
    "W_init = tf.random_normal(\n",
    "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "W = tf.Variable(W_init, name=\"W\")\n",
    "\n",
    "batch_size = tf.shape(X)[0]\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")\n",
    "\n",
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                       name=\"caps1_output_expanded\")\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                   name=\"caps1_output_tile\")\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                             name=\"caps1_output_tiled\")\n",
    "\n",
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
    "                            name=\"caps2_predicted\")\n",
    "\n",
    "# Dynamic Routing algorithm\n",
    "# Round 1\n",
    "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
    "                       dtype=np.float32, name=\"raw_weights\")\n",
    "routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")\n",
    "\n",
    "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
    "                                   name=\"weighted_predictions\")\n",
    "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
    "                             name=\"weighted_sum\")\n",
    "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
    "                              name=\"caps2_output_round_1\")\n",
    "\n",
    "caps2_output_round_1_tiled = tf.tile(\n",
    "    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_1_tiled\")\n",
    "\n",
    "agreement1 = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
    "                      transpose_a=True, name=\"agreement1\")\n",
    "# Round 2\n",
    "# Routing weight update\n",
    "raw_weights_round_2 = tf.add(raw_weights, agreement1,\n",
    "                             name=\"raw_weights_round_2\")\n",
    "routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_2\")\n",
    "weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_2\")\n",
    "weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_2\")\n",
    "caps2_output_round_2 = squash(weighted_sum_round_2,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_2\")\n",
    "caps2_output_round_2_tiled = tf.tile(\n",
    "    caps2_output_round_2, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_2_tiled\")\n",
    "\n",
    "agreement2 = tf.matmul(caps2_predicted, caps2_output_round_2_tiled,\n",
    "                      transpose_a=True, name=\"agreement2\")\n",
    "\n",
    "# Round 3\n",
    "# Routing weight update\n",
    "raw_weights_round_3 = tf.add(raw_weights_round_2, agreement2,\n",
    "                             name=\"raw_weights_round_3\")\n",
    "routing_weights_round_3 = tf.nn.softmax(raw_weights_round_3,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_3\")\n",
    "weighted_predictions_round_3 = tf.multiply(routing_weights_round_3,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_3\")\n",
    "weighted_sum_round_3 = tf.reduce_sum(weighted_predictions_round_3,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_3\")\n",
    "caps2_output_round_3 = squash(weighted_sum_round_3,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_3\")\n",
    "caps2_output_round_3_tiled = tf.tile(\n",
    "    caps2_output_round_3, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_3_tiled\")\n",
    "\n",
    "agreement3 = tf.matmul(caps2_predicted, caps2_output_round_3_tiled,\n",
    "                      transpose_a=True, name=\"agreement3\")\n",
    "\n",
    "# Round 4\n",
    "# Routing weight update\n",
    "raw_weights_round_4 = tf.add(raw_weights_round_3, agreement3,\n",
    "                             name=\"raw_weights_round_4\")\n",
    "routing_weights_round_4 = tf.nn.softmax(raw_weights_round_4,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_4\")\n",
    "weighted_predictions_round_4 = tf.multiply(routing_weights_round_4,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_4\")\n",
    "weighted_sum_round_4 = tf.reduce_sum(weighted_predictions_round_4,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_4\")\n",
    "caps2_output_round_4 = squash(weighted_sum_round_4,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_4\")\n",
    "\"\"\"caps2_output_round_4_tiled = tf.tile(\n",
    "    caps2_output_round_4, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_4_tiled\")\n",
    "\n",
    "agreement4 = tf.matmul(caps2_predicted, caps2_output_round_4_tiled,\n",
    "                      transpose_a=True, name=\"agreement3\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "caps2_output = caps2_output_round_4\n",
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)\n",
    "\n",
    "y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")\n",
    "\n",
    "\n",
    "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n",
    "\n",
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
    "\n",
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")\n",
    "\n",
    "m_plus = 0.95\n",
    "m_minus = 0.05\n",
    "lambda_ = 100\n",
    "\n",
    "T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")\n",
    "\n",
    "caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
    "                              name=\"caps2_output_norm\")\n",
    "\n",
    "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
    "                              name=\"present_error_raw\")\n",
    "present_error = tf.reshape(present_error_raw, shape=(-1, 2),\n",
    "                           name=\"present_error\")\n",
    "present_error\n",
    "\n",
    "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
    "                             name=\"absent_error_raw\")\n",
    "absent_error = tf.reshape(absent_error_raw, shape=(-1, 2),\n",
    "                          name=\"absent_error\")\n",
    "\n",
    "# Loss Function\n",
    "\n",
    "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
    "           name=\"L\")\n",
    "\n",
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n",
    "\n",
    "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
    "                                               name=\"mask_with_labels\")\n",
    "\n",
    "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                                 lambda: y,        # if True\n",
    "                                 lambda: y_pred,   # if False\n",
    "                                 name=\"reconstruction_targets\")\n",
    "\n",
    "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
    "                                 depth=caps2_n_caps,\n",
    "                                 name=\"reconstruction_mask\")\n",
    "\n",
    "reconstruction_mask_reshaped = tf.reshape(\n",
    "    reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],\n",
    "    name=\"reconstruction_mask_reshaped\")\n",
    "\n",
    "caps2_output_masked = tf.multiply(\n",
    "    caps2_output, reconstruction_mask_reshaped,\n",
    "    name=\"caps2_output_masked\")\n",
    "\n",
    "decoder_input = tf.reshape(caps2_output_masked,\n",
    "                           [-1, caps2_n_caps * caps2_n_dims],\n",
    "                           name=\"decoder_input\")\n",
    "\n",
    "n_hidden1 = 16\n",
    "n_hidden2 = 32\n",
    "n_output = 5*5\n",
    "\n",
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
    "                                     activation=tf.nn.sigmoid,\n",
    "                                     name=\"decoder_output\")\n",
    "\n",
    "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "squared_difference = tf.square(X_flat - decoder_output,\n",
    "                               name=\"squared_difference\")\n",
    "reconstruction_loss = tf.reduce_mean(squared_difference,\n",
    "                                    name=\"reconstruction_loss\")\n",
    "\n",
    "alpha = 0.0005\n",
    "\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")\n",
    "\n",
    "\n",
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Val accuracy: 99.8527%  Loss: 0.047239 (improved)\n",
      "Epoch: 2  Val accuracy: 99.8725%  Loss: 0.035852 (improved)\n",
      "Epoch: 3  Val accuracy: 99.8879%  Loss: 0.029497 (improved)\n",
      "Epoch: 4  Val accuracy: 99.9121%  Loss: 0.027808 (improved)\n",
      "Epoch: 5  Val accuracy: 99.9209%  Loss: 0.027297 (improved)\n",
      "Epoch: 6  Val accuracy: 99.9077%  Loss: 0.027483\n",
      "Epoch: 7  Val accuracy: 99.9187%  Loss: 0.026489 (improved)\n",
      "Epoch: 8  Val accuracy: 99.9253%  Loss: 0.026968\n",
      "Epoch: 9  Val accuracy: 99.9187%  Loss: 0.027316\n",
      "Epoch: 10  Val accuracy: 99.9253%  Loss: 0.027482\n",
      "Epoch: 11  Val accuracy: 99.9209%  Loss: 0.027683\n",
      "Epoch: 12  Val accuracy: 99.9319%  Loss: 0.028037\n",
      "Epoch: 13  Val accuracy: 99.9165%  Loss: 0.027182\n",
      "Epoch: 14  Val accuracy: 99.9275%  Loss: 0.028008\n",
      "Epoch: 15  Val accuracy: 99.9253%  Loss: 0.026290 (improved)\n",
      "Epoch: 16  Val accuracy: 99.9231%  Loss: 0.027543\n",
      "Epoch: 17  Val accuracy: 99.9363%  Loss: 0.028715\n",
      "Epoch: 18  Val accuracy: 99.9231%  Loss: 0.027996\n",
      "Epoch: 19  Val accuracy: 99.9143%  Loss: 0.028590\n",
      "Epoch: 20  Val accuracy: 99.9033%  Loss: 0.030100\n",
      "Epoch: 21  Val accuracy: 99.9231%  Loss: 0.027595\n",
      "Epoch: 22  Val accuracy: 99.9231%  Loss: 0.027042\n",
      "Epoch: 23  Val accuracy: 99.9253%  Loss: 0.027796\n",
      "Epoch: 24  Val accuracy: 99.9385%  Loss: 0.026032 (improved)\n",
      "Epoch: 25  Val accuracy: 99.9209%  Loss: 0.029579\n",
      "Epoch: 26  Val accuracy: 99.9341%  Loss: 0.029867\n",
      "Epoch: 27  Val accuracy: 99.9341%  Loss: 0.025115 (improved)\n",
      "Epoch: 28  Val accuracy: 99.9363%  Loss: 0.025747\n",
      "Epoch: 29  Val accuracy: 99.9341%  Loss: 0.026964\n",
      "Epoch: 30  Val accuracy: 99.9341%  Loss: 0.027009\n",
      "Epoch: 31  Val accuracy: 99.9385%  Loss: 0.026600\n",
      "Epoch: 32  Val accuracy: 99.9385%  Loss: 0.027715\n",
      "Epoch: 33  Val accuracy: 99.9407%  Loss: 0.026722\n",
      "Epoch: 34  Val accuracy: 99.9385%  Loss: 0.031435\n",
      "Epoch: 35  Val accuracy: 99.9275%  Loss: 0.031787\n",
      "Epoch: 36  Val accuracy: 99.9275%  Loss: 0.028840\n",
      "Epoch: 37  Val accuracy: 99.9363%  Loss: 0.027961\n",
      "Epoch: 38  Val accuracy: 99.9297%  Loss: 0.027438\n",
      "Epoch: 39  Val accuracy: 99.9319%  Loss: 0.029032\n",
      "Epoch: 40  Val accuracy: 99.9407%  Loss: 0.030210\n",
      "Epoch: 41  Val accuracy: 99.9363%  Loss: 0.026770\n",
      "Epoch: 42  Val accuracy: 99.9319%  Loss: 0.027873\n",
      "Epoch: 43  Val accuracy: 99.9341%  Loss: 0.030289\n",
      "Epoch: 44  Val accuracy: 99.9253%  Loss: 0.030093\n",
      "Epoch: 45  Val accuracy: 99.9297%  Loss: 0.029083\n",
      "Epoch: 46  Val accuracy: 99.9231%  Loss: 0.033205\n",
      "Epoch: 47  Val accuracy: 99.9275%  Loss: 0.028022\n",
      "Epoch: 48  Val accuracy: 99.9319%  Loss: 0.028920\n",
      "Epoch: 49  Val accuracy: 99.9407%  Loss: 0.029021\n",
      "Epoch: 50  Val accuracy: 99.9319%  Loss: 0.029969\n",
      "Epoch: 51  Val accuracy: 99.9407%  Loss: 0.029497\n",
      "Epoch: 52  Val accuracy: 99.9275%  Loss: 0.029578\n",
      "Epoch: 53  Val accuracy: 99.9253%  Loss: 0.033346\n",
      "Epoch: 54  Val accuracy: 99.9385%  Loss: 0.028911\n",
      "Epoch: 55  Val accuracy: 99.9341%  Loss: 0.033636\n",
      "Epoch: 56  Val accuracy: 99.9385%  Loss: 0.030863\n",
      "Epoch: 57  Val accuracy: 99.9341%  Loss: 0.030669\n",
      "Epoch: 58  Val accuracy: 99.9231%  Loss: 0.029351\n",
      "Epoch: 59  Val accuracy: 99.9385%  Loss: 0.029976\n",
      "Epoch: 60  Val accuracy: 99.9341%  Loss: 0.029668\n",
      "Epoch: 61  Val accuracy: 99.9363%  Loss: 0.031043\n",
      "Epoch: 62  Val accuracy: 99.9297%  Loss: 0.031965\n",
      "Epoch: 63  Val accuracy: 99.9363%  Loss: 0.031718\n",
      "Epoch: 64  Val accuracy: 99.9319%  Loss: 0.036142\n",
      "Epoch: 65  Val accuracy: 99.9363%  Loss: 0.028848\n",
      "Epoch: 66  Val accuracy: 99.9341%  Loss: 0.029642\n",
      "Epoch: 67  Val accuracy: 99.9341%  Loss: 0.031102\n",
      "Epoch: 68  Val accuracy: 99.9275%  Loss: 0.031420\n",
      "Epoch: 69  Val accuracy: 99.9275%  Loss: 0.030907\n",
      "Epoch: 70  Val accuracy: 99.9319%  Loss: 0.033124\n",
      "Epoch: 71  Val accuracy: 99.9297%  Loss: 0.029912\n",
      "Epoch: 72  Val accuracy: 99.9297%  Loss: 0.033558\n",
      "Epoch: 73  Val accuracy: 99.9297%  Loss: 0.038806\n",
      "Epoch: 74  Val accuracy: 99.9253%  Loss: 0.031352\n",
      "Epoch: 75  Val accuracy: 99.9253%  Loss: 0.032001\n",
      "Epoch: 76  Val accuracy: 99.9407%  Loss: 0.032145\n",
      "Epoch: 77  Val accuracy: 99.9319%  Loss: 0.032886\n",
      "Epoch: 78  Val accuracy: 99.9363%  Loss: 0.034277\n",
      "Epoch: 79  Val accuracy: 99.9341%  Loss: 0.033582\n",
      "Epoch: 80  Val accuracy: 99.9363%  Loss: 0.034041\n",
      "Epoch: 81  Val accuracy: 99.9341%  Loss: 0.034617\n",
      "Epoch: 82  Val accuracy: 99.9297%  Loss: 0.034784\n",
      "Epoch: 83  Val accuracy: 99.9297%  Loss: 0.031652\n",
      "Epoch: 84  Val accuracy: 99.9319%  Loss: 0.035179\n",
      "Epoch: 85  Val accuracy: 99.9231%  Loss: 0.033048\n",
      "Epoch: 86  Val accuracy: 99.9407%  Loss: 0.032098\n",
      "Epoch: 87  Val accuracy: 99.9297%  Loss: 0.034157\n",
      "Epoch: 88  Val accuracy: 99.9319%  Loss: 0.033566\n",
      "Epoch: 89  Val accuracy: 99.9253%  Loss: 0.032555\n",
      "Epoch: 90  Val accuracy: 99.9275%  Loss: 0.031820\n",
      "Epoch: 91  Val accuracy: 99.9231%  Loss: 0.033874\n",
      "Epoch: 92  Val accuracy: 99.9297%  Loss: 0.033797\n",
      "Epoch: 93  Val accuracy: 99.9209%  Loss: 0.034402\n",
      "Epoch: 94  Val accuracy: 99.9253%  Loss: 0.040911\n",
      "Epoch: 95  Val accuracy: 99.9209%  Loss: 0.033021\n",
      "Epoch: 96  Val accuracy: 99.9253%  Loss: 0.037155\n",
      "Epoch: 97  Val accuracy: 99.9297%  Loss: 0.030535\n",
      "Epoch: 98  Val accuracy: 99.9275%  Loss: 0.036394\n",
      "Epoch: 99  Val accuracy: 99.9231%  Loss: 0.031826\n",
      "Epoch: 100  Val accuracy: 99.9297%  Loss: 0.033912\n",
      "Epoch: 101  Val accuracy: 99.9319%  Loss: 0.032950\n",
      "Epoch: 102  Val accuracy: 99.9253%  Loss: 0.035308\n",
      "Epoch: 103  Val accuracy: 99.9275%  Loss: 0.035197\n",
      "Epoch: 104  Val accuracy: 99.9187%  Loss: 0.034993\n",
      "Epoch: 105  Val accuracy: 99.9253%  Loss: 0.033603\n",
      "Epoch: 106  Val accuracy: 99.9319%  Loss: 0.035687\n",
      "Epoch: 107  Val accuracy: 99.9253%  Loss: 0.034919\n",
      "Epoch: 108  Val accuracy: 99.9231%  Loss: 0.034959\n",
      "Epoch: 109  Val accuracy: 99.9297%  Loss: 0.035186\n",
      "Epoch: 110  Val accuracy: 99.9341%  Loss: 0.033669\n",
      "Epoch: 111  Val accuracy: 99.9297%  Loss: 0.035629\n",
      "Epoch: 112  Val accuracy: 99.9275%  Loss: 0.036851\n",
      "Epoch: 113  Val accuracy: 99.9297%  Loss: 0.034890\n",
      "Epoch: 114  Val accuracy: 99.9275%  Loss: 0.034768\n",
      "Epoch: 115  Val accuracy: 99.9253%  Loss: 0.035068\n",
      "Epoch: 116  Val accuracy: 99.9253%  Loss: 0.036032\n",
      "Epoch: 117  Val accuracy: 99.9253%  Loss: 0.036805\n",
      "Epoch: 118  Val accuracy: 99.9319%  Loss: 0.036905\n",
      "Epoch: 119  Val accuracy: 99.9275%  Loss: 0.034410\n",
      "Epoch: 120  Val accuracy: 99.9297%  Loss: 0.036834\n",
      "Epoch: 121  Val accuracy: 99.9297%  Loss: 0.033496\n",
      "Epoch: 122  Val accuracy: 99.9275%  Loss: 0.035905\n",
      "Epoch: 123  Val accuracy: 99.9319%  Loss: 0.034750\n",
      "Epoch: 124  Val accuracy: 99.9341%  Loss: 0.035154\n",
      "Epoch: 125  Val accuracy: 99.9253%  Loss: 0.036660\n",
      "Epoch: 126  Val accuracy: 99.9275%  Loss: 0.036041\n",
      "Epoch: 127  Val accuracy: 99.9275%  Loss: 0.033946\n",
      "Epoch: 128  Val accuracy: 99.9231%  Loss: 0.036153\n",
      "Epoch: 129  Val accuracy: 99.9319%  Loss: 0.033920\n",
      "Epoch: 130  Val accuracy: 99.9297%  Loss: 0.036360\n",
      "Epoch: 131  Val accuracy: 99.9275%  Loss: 0.034899\n",
      "Epoch: 132  Val accuracy: 99.9253%  Loss: 0.032254\n",
      "Epoch: 133  Val accuracy: 99.9319%  Loss: 0.035846\n",
      "Epoch: 134  Val accuracy: 99.9297%  Loss: 0.035228\n",
      "Epoch: 135  Val accuracy: 99.9231%  Loss: 0.035779\n",
      "Epoch: 136  Val accuracy: 99.9319%  Loss: 0.035257\n",
      "Epoch: 137  Val accuracy: 99.9319%  Loss: 0.036374\n",
      "Epoch: 138  Val accuracy: 99.9363%  Loss: 0.032132\n",
      "Epoch: 139  Val accuracy: 99.9275%  Loss: 0.033818\n",
      "Epoch: 140  Val accuracy: 99.9341%  Loss: 0.035723\n",
      "Epoch: 141  Val accuracy: 99.9253%  Loss: 0.035035\n",
      "Epoch: 142  Val accuracy: 99.9187%  Loss: 0.037166\n",
      "Epoch: 143  Val accuracy: 99.9253%  Loss: 0.034798\n",
      "Epoch: 144  Val accuracy: 99.9253%  Loss: 0.035963\n",
      "Epoch: 145  Val accuracy: 99.9253%  Loss: 0.036165\n",
      "Epoch: 146  Val accuracy: 99.9253%  Loss: 0.036200\n",
      "Epoch: 147  Val accuracy: 99.9275%  Loss: 0.036478\n",
      "Epoch: 148  Val accuracy: 99.9297%  Loss: 0.038103\n",
      "Epoch: 149  Val accuracy: 99.9297%  Loss: 0.036112\n",
      "Epoch: 150  Val accuracy: 99.9297%  Loss: 0.035565\n",
      "Epoch: 151  Val accuracy: 99.9275%  Loss: 0.036258\n",
      "Epoch: 152  Val accuracy: 99.9253%  Loss: 0.036640\n",
      "Epoch: 153  Val accuracy: 99.9319%  Loss: 0.036218\n",
      "Epoch: 154  Val accuracy: 99.9165%  Loss: 0.037404\n",
      "Epoch: 155  Val accuracy: 99.9319%  Loss: 0.037025\n",
      "Epoch: 156  Val accuracy: 99.9297%  Loss: 0.037576\n",
      "Epoch: 157  Val accuracy: 99.9341%  Loss: 0.036271\n",
      "Epoch: 158  Val accuracy: 99.9231%  Loss: 0.035968\n",
      "Epoch: 159  Val accuracy: 99.9297%  Loss: 0.034994\n",
      "Epoch: 160  Val accuracy: 99.9385%  Loss: 0.036255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 161  Val accuracy: 99.9297%  Loss: 0.036110\n",
      "Epoch: 162  Val accuracy: 99.9297%  Loss: 0.034336\n",
      "Epoch: 163  Val accuracy: 99.9341%  Loss: 0.034813\n",
      "Epoch: 164  Val accuracy: 99.9187%  Loss: 0.036823\n",
      "Epoch: 165  Val accuracy: 99.9319%  Loss: 0.034217\n",
      "Epoch: 166  Val accuracy: 99.9341%  Loss: 0.033772\n",
      "Epoch: 167  Val accuracy: 99.9319%  Loss: 0.035242\n",
      "Epoch: 168  Val accuracy: 99.9297%  Loss: 0.036157\n",
      "Epoch: 169  Val accuracy: 99.9297%  Loss: 0.035891\n",
      "Epoch: 170  Val accuracy: 99.9297%  Loss: 0.036367\n",
      "Epoch: 171  Val accuracy: 99.9253%  Loss: 0.038890\n",
      "Epoch: 172  Val accuracy: 99.9297%  Loss: 0.035324\n",
      "Epoch: 173  Val accuracy: 99.9385%  Loss: 0.035722\n",
      "Epoch: 174  Val accuracy: 99.9319%  Loss: 0.034998\n",
      "Epoch: 175  Val accuracy: 99.9341%  Loss: 0.034417\n",
      "Epoch: 176  Val accuracy: 99.9319%  Loss: 0.034053\n",
      "Epoch: 177  Val accuracy: 99.9363%  Loss: 0.036743\n",
      "Epoch: 178  Val accuracy: 99.9297%  Loss: 0.035736\n",
      "Epoch: 179  Val accuracy: 99.9297%  Loss: 0.033762\n",
      "Epoch: 180  Val accuracy: 99.9363%  Loss: 0.032226\n",
      "Epoch: 181  Val accuracy: 99.9363%  Loss: 0.037815\n",
      "Epoch: 182  Val accuracy: 99.9209%  Loss: 0.036212\n",
      "Epoch: 183  Val accuracy: 99.9297%  Loss: 0.035935\n",
      "Epoch: 184  Val accuracy: 99.9319%  Loss: 0.032956\n",
      "Epoch: 185  Val accuracy: 99.9341%  Loss: 0.036289\n",
      "Epoch: 186  Val accuracy: 99.9297%  Loss: 0.035270\n",
      "Epoch: 187  Val accuracy: 99.9297%  Loss: 0.036608\n",
      "Epoch: 188  Val accuracy: 99.9231%  Loss: 0.035918\n",
      "Epoch: 189  Val accuracy: 99.9319%  Loss: 0.032912\n",
      "Epoch: 190  Val accuracy: 99.9319%  Loss: 0.034753\n",
      "Epoch: 191  Val accuracy: 99.9341%  Loss: 0.037952\n",
      "Epoch: 192  Val accuracy: 99.9319%  Loss: 0.036952\n",
      "Epoch: 193  Val accuracy: 99.9275%  Loss: 0.035488\n",
      "Epoch: 194  Val accuracy: 99.9341%  Loss: 0.035395\n",
      "Epoch: 195  Val accuracy: 99.9319%  Loss: 0.037486\n",
      "Epoch: 196  Val accuracy: 99.9253%  Loss: 0.036299\n",
      "Epoch: 197  Val accuracy: 99.9319%  Loss: 0.036596\n",
      "Epoch: 198  Val accuracy: 99.9319%  Loss: 0.033881\n",
      "Epoch: 199  Val accuracy: 99.9385%  Loss: 0.037093\n",
      "Epoch: 200  Val accuracy: 99.9363%  Loss: 0.033607\n",
      "Epoch: 201  Val accuracy: 99.9341%  Loss: 0.036647\n",
      "Epoch: 202  Val accuracy: 99.9341%  Loss: 0.034853\n",
      "Epoch: 203  Val accuracy: 99.9209%  Loss: 0.035074\n",
      "Epoch: 204  Val accuracy: 99.9341%  Loss: 0.035522\n",
      "Epoch: 205  Val accuracy: 99.9319%  Loss: 0.034777\n",
      "Epoch: 206  Val accuracy: 99.9253%  Loss: 0.033058\n",
      "Epoch: 207  Val accuracy: 99.9319%  Loss: 0.037692\n",
      "Epoch: 208  Val accuracy: 99.9363%  Loss: 0.036691\n",
      "Epoch: 209  Val accuracy: 99.9319%  Loss: 0.035316\n",
      "Epoch: 210  Val accuracy: 99.9297%  Loss: 0.037282\n",
      "Epoch: 211  Val accuracy: 99.9275%  Loss: 0.034912\n",
      "Epoch: 212  Val accuracy: 99.9319%  Loss: 0.035530\n",
      "Epoch: 213  Val accuracy: 99.9341%  Loss: 0.032195\n",
      "Epoch: 214  Val accuracy: 99.9297%  Loss: 0.035804\n",
      "Epoch: 215  Val accuracy: 99.9319%  Loss: 0.034097\n",
      "Epoch: 216  Val accuracy: 99.9363%  Loss: 0.035772\n",
      "Epoch: 217  Val accuracy: 99.9385%  Loss: 0.037009\n",
      "Epoch: 218  Val accuracy: 99.9297%  Loss: 0.035524\n",
      "Epoch: 219  Val accuracy: 99.9363%  Loss: 0.034570\n",
      "Epoch: 220  Val accuracy: 99.9363%  Loss: 0.035818\n",
      "Epoch: 221  Val accuracy: 99.9341%  Loss: 0.034406\n",
      "Epoch: 222  Val accuracy: 99.9341%  Loss: 0.035137\n",
      "Epoch: 223  Val accuracy: 99.9341%  Loss: 0.035175\n",
      "Epoch: 224  Val accuracy: 99.9341%  Loss: 0.036077\n",
      "Epoch: 225  Val accuracy: 99.9253%  Loss: 0.037612\n",
      "Epoch: 226  Val accuracy: 99.9319%  Loss: 0.036063\n",
      "Epoch: 227  Val accuracy: 99.9363%  Loss: 0.034741\n",
      "Epoch: 228  Val accuracy: 99.9297%  Loss: 0.036565\n",
      "Epoch: 229  Val accuracy: 99.9341%  Loss: 0.035611\n",
      "Epoch: 230  Val accuracy: 99.9319%  Loss: 0.035622\n",
      "Epoch: 231  Val accuracy: 99.9319%  Loss: 0.038511\n",
      "Epoch: 232  Val accuracy: 99.9341%  Loss: 0.034655\n",
      "Epoch: 233  Val accuracy: 99.9341%  Loss: 0.035005\n",
      "Epoch: 234  Val accuracy: 99.9385%  Loss: 0.034442\n",
      "Epoch: 235  Val accuracy: 99.9341%  Loss: 0.035574\n",
      "Epoch: 236  Val accuracy: 99.9319%  Loss: 0.033021\n",
      "Epoch: 237  Val accuracy: 99.9407%  Loss: 0.035315\n",
      "Epoch: 238  Val accuracy: 99.9341%  Loss: 0.036120\n",
      "Epoch: 239  Val accuracy: 99.9385%  Loss: 0.036820\n",
      "Epoch: 240  Val accuracy: 99.9363%  Loss: 0.034946\n",
      "Epoch: 241  Val accuracy: 99.9385%  Loss: 0.036942\n",
      "Epoch: 242  Val accuracy: 99.9341%  Loss: 0.036173\n",
      "Epoch: 243  Val accuracy: 99.9319%  Loss: 0.035872\n",
      "Epoch: 244  Val accuracy: 99.9363%  Loss: 0.034734\n",
      "Epoch: 245  Val accuracy: 99.9385%  Loss: 0.033991\n",
      "Epoch: 246  Val accuracy: 99.9341%  Loss: 0.035491\n",
      "Epoch: 247  Val accuracy: 99.9341%  Loss: 0.035669\n",
      "Epoch: 248  Val accuracy: 99.9319%  Loss: 0.036584\n",
      "Epoch: 249  Val accuracy: 99.9385%  Loss: 0.036414\n",
      "Epoch: 250  Val accuracy: 99.9385%  Loss: 0.035721\n",
      "Epoch: 251  Val accuracy: 99.9385%  Loss: 0.036521\n",
      "Epoch: 252  Val accuracy: 99.9341%  Loss: 0.037336\n",
      "Epoch: 253  Val accuracy: 99.9297%  Loss: 0.036100\n",
      "Epoch: 254  Val accuracy: 99.9341%  Loss: 0.035614\n",
      "Epoch: 255  Val accuracy: 99.9341%  Loss: 0.036732\n",
      "Epoch: 256  Val accuracy: 99.9341%  Loss: 0.035665\n",
      "Epoch: 257  Val accuracy: 99.9341%  Loss: 0.034848\n",
      "Epoch: 258  Val accuracy: 99.9341%  Loss: 0.036155\n",
      "Epoch: 259  Val accuracy: 99.9385%  Loss: 0.035941\n",
      "Epoch: 260  Val accuracy: 99.9319%  Loss: 0.035138\n",
      "Epoch: 261  Val accuracy: 99.9341%  Loss: 0.035865\n",
      "Epoch: 262  Val accuracy: 99.9297%  Loss: 0.037579\n",
      "Epoch: 263  Val accuracy: 99.9341%  Loss: 0.037124\n",
      "Epoch: 264  Val accuracy: 99.9341%  Loss: 0.036298\n",
      "Epoch: 265  Val accuracy: 99.9341%  Loss: 0.035960\n",
      "Epoch: 266  Val accuracy: 99.9341%  Loss: 0.036949\n",
      "Epoch: 267  Val accuracy: 99.9341%  Loss: 0.037600\n",
      "Epoch: 268  Val accuracy: 99.9407%  Loss: 0.036303\n",
      "Epoch: 269  Val accuracy: 99.9341%  Loss: 0.037097\n",
      "Epoch: 270  Val accuracy: 99.9319%  Loss: 0.037071\n",
      "Epoch: 271  Val accuracy: 99.9363%  Loss: 0.035481\n",
      "Epoch: 272  Val accuracy: 99.9297%  Loss: 0.035985\n",
      "Epoch: 273  Val accuracy: 99.9341%  Loss: 0.034729\n",
      "Epoch: 274  Val accuracy: 99.9341%  Loss: 0.035183\n",
      "Epoch: 275  Val accuracy: 99.9319%  Loss: 0.038399\n",
      "Epoch: 276  Val accuracy: 99.9341%  Loss: 0.034499\n",
      "Epoch: 277  Val accuracy: 99.9341%  Loss: 0.034869\n",
      "Epoch: 278  Val accuracy: 99.9407%  Loss: 0.035275\n",
      "Epoch: 279  Val accuracy: 99.9341%  Loss: 0.035068\n",
      "Epoch: 280  Val accuracy: 99.9363%  Loss: 0.035623\n",
      "Epoch: 281  Val accuracy: 99.9319%  Loss: 0.034667\n",
      "Epoch: 282  Val accuracy: 99.9297%  Loss: 0.036507\n",
      "Epoch: 283  Val accuracy: 99.9319%  Loss: 0.035692\n",
      "Epoch: 284  Val accuracy: 99.9363%  Loss: 0.036749\n",
      "Epoch: 285  Val accuracy: 99.9341%  Loss: 0.035318\n",
      "Epoch: 286  Val accuracy: 99.9275%  Loss: 0.035409\n",
      "Epoch: 287  Val accuracy: 99.9341%  Loss: 0.036824\n",
      "Epoch: 288  Val accuracy: 99.9385%  Loss: 0.037595\n",
      "Epoch: 289  Val accuracy: 99.9341%  Loss: 0.035377\n",
      "Epoch: 290  Val accuracy: 99.9385%  Loss: 0.035609\n",
      "Epoch: 291  Val accuracy: 99.9363%  Loss: 0.034782\n",
      "Epoch: 292  Val accuracy: 99.9341%  Loss: 0.036982\n",
      "Epoch: 293  Val accuracy: 99.9363%  Loss: 0.036716\n",
      "Epoch: 294  Val accuracy: 99.9363%  Loss: 0.035289\n",
      "Epoch: 295  Val accuracy: 99.9319%  Loss: 0.035793\n",
      "Epoch: 296  Val accuracy: 99.9363%  Loss: 0.036663\n",
      "Epoch: 297  Val accuracy: 99.9341%  Loss: 0.035052\n",
      "Epoch: 298  Val accuracy: 99.9385%  Loss: 0.036090\n",
      "Epoch: 299  Val accuracy: 99.9341%  Loss: 0.037002\n",
      "Epoch: 300  Val accuracy: 99.9363%  Loss: 0.036270\n",
      "Epoch: 301  Val accuracy: 99.9341%  Loss: 0.037400\n",
      "Epoch: 302  Val accuracy: 99.9341%  Loss: 0.037189\n",
      "Epoch: 303  Val accuracy: 99.9231%  Loss: 0.042051\n",
      "Epoch: 304  Val accuracy: 99.9363%  Loss: 0.038080\n",
      "Epoch: 305  Val accuracy: 99.9341%  Loss: 0.038184\n",
      "Epoch: 306  Val accuracy: 99.9319%  Loss: 0.036824\n",
      "Epoch: 307  Val accuracy: 99.9297%  Loss: 0.036914\n",
      "Epoch: 308  Val accuracy: 99.9341%  Loss: 0.035704\n",
      "Epoch: 309  Val accuracy: 99.9341%  Loss: 0.038791\n",
      "Epoch: 310  Val accuracy: 99.9363%  Loss: 0.037093\n",
      "Epoch: 311  Val accuracy: 99.9341%  Loss: 0.036576\n",
      "Epoch: 312  Val accuracy: 99.9341%  Loss: 0.038358\n",
      "Epoch: 313  Val accuracy: 99.9363%  Loss: 0.036905\n",
      "Epoch: 314  Val accuracy: 99.9341%  Loss: 0.038650\n",
      "Epoch: 315  Val accuracy: 99.9341%  Loss: 0.038539\n",
      "Epoch: 316  Val accuracy: 99.9341%  Loss: 0.038412\n",
      "Epoch: 317  Val accuracy: 99.9341%  Loss: 0.038674\n",
      "Epoch: 318  Val accuracy: 99.9341%  Loss: 0.040528\n",
      "Epoch: 319  Val accuracy: 99.9341%  Loss: 0.039194\n",
      "Epoch: 320  Val accuracy: 99.9341%  Loss: 0.037158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 321  Val accuracy: 99.9341%  Loss: 0.036867\n",
      "Epoch: 322  Val accuracy: 99.9275%  Loss: 0.038523\n",
      "Epoch: 323  Val accuracy: 99.9297%  Loss: 0.039067\n",
      "Epoch: 324  Val accuracy: 99.9385%  Loss: 0.038724\n",
      "Epoch: 325  Val accuracy: 99.9341%  Loss: 0.038530\n",
      "Epoch: 326  Val accuracy: 99.9341%  Loss: 0.039078\n",
      "Epoch: 327  Val accuracy: 99.9319%  Loss: 0.036746\n",
      "Epoch: 328  Val accuracy: 99.9385%  Loss: 0.039579\n",
      "Epoch: 329  Val accuracy: 99.9275%  Loss: 0.041558\n",
      "Epoch: 330  Val accuracy: 99.9341%  Loss: 0.039157\n",
      "Epoch: 331  Val accuracy: 99.9297%  Loss: 0.039231\n",
      "Epoch: 332  Val accuracy: 99.9319%  Loss: 0.037469\n",
      "Epoch: 333  Val accuracy: 99.9341%  Loss: 0.038346\n",
      "Epoch: 334  Val accuracy: 99.9363%  Loss: 0.038570\n",
      "Epoch: 335  Val accuracy: 99.9341%  Loss: 0.040412\n",
      "Epoch: 336  Val accuracy: 99.9341%  Loss: 0.038228\n",
      "Epoch: 337  Val accuracy: 99.9319%  Loss: 0.038619\n",
      "Epoch: 338  Val accuracy: 99.9363%  Loss: 0.038655\n",
      "Epoch: 339  Val accuracy: 99.9341%  Loss: 0.038401\n",
      "Epoch: 340  Val accuracy: 99.9385%  Loss: 0.038058\n",
      "Epoch: 341  Val accuracy: 99.9363%  Loss: 0.038698\n",
      "Epoch: 342  Val accuracy: 99.9319%  Loss: 0.037832\n",
      "Epoch: 343  Val accuracy: 99.9341%  Loss: 0.038858\n",
      "Epoch: 344  Val accuracy: 99.9341%  Loss: 0.039458\n",
      "Epoch: 345  Val accuracy: 99.9385%  Loss: 0.039086\n",
      "Epoch: 346  Val accuracy: 99.9385%  Loss: 0.039014\n",
      "Epoch: 347  Val accuracy: 99.9341%  Loss: 0.038226\n",
      "Epoch: 348  Val accuracy: 99.9363%  Loss: 0.039343\n",
      "Epoch: 349  Val accuracy: 99.9363%  Loss: 0.037598\n",
      "Epoch: 350  Val accuracy: 99.9319%  Loss: 0.041339\n",
      "Epoch: 351  Val accuracy: 99.9275%  Loss: 0.042270\n",
      "Epoch: 352  Val accuracy: 99.9319%  Loss: 0.036776\n",
      "Epoch: 353  Val accuracy: 99.9319%  Loss: 0.039037\n",
      "Epoch: 354  Val accuracy: 99.9385%  Loss: 0.038692\n",
      "Epoch: 355  Val accuracy: 99.9319%  Loss: 0.041808\n",
      "Epoch: 356  Val accuracy: 99.9319%  Loss: 0.040400\n",
      "Epoch: 357  Val accuracy: 99.9319%  Loss: 0.039617\n",
      "Epoch: 358  Val accuracy: 99.9319%  Loss: 0.037115\n",
      "Epoch: 359  Val accuracy: 99.9341%  Loss: 0.037591\n",
      "Epoch: 360  Val accuracy: 99.9363%  Loss: 0.037523\n",
      "Epoch: 361  Val accuracy: 99.9385%  Loss: 0.039114\n",
      "Epoch: 362  Val accuracy: 99.9341%  Loss: 0.038278\n",
      "Epoch: 363  Val accuracy: 99.9319%  Loss: 0.041226\n",
      "Epoch: 364  Val accuracy: 99.9275%  Loss: 0.041104\n",
      "Epoch: 365  Val accuracy: 99.9341%  Loss: 0.038506\n",
      "Epoch: 366  Val accuracy: 99.9341%  Loss: 0.039961\n",
      "Epoch: 367  Val accuracy: 99.9363%  Loss: 0.037609\n",
      "Epoch: 368  Val accuracy: 99.9341%  Loss: 0.039069\n",
      "Epoch: 369  Val accuracy: 99.9319%  Loss: 0.039055\n",
      "Epoch: 370  Val accuracy: 99.9341%  Loss: 0.038885\n",
      "Epoch: 371  Val accuracy: 99.9341%  Loss: 0.038679\n",
      "Epoch: 372  Val accuracy: 99.9341%  Loss: 0.038885\n",
      "Epoch: 373  Val accuracy: 99.9253%  Loss: 0.040722\n",
      "Epoch: 374  Val accuracy: 99.9319%  Loss: 0.039325\n",
      "Epoch: 375  Val accuracy: 99.9253%  Loss: 0.042117\n",
      "Epoch: 376  Val accuracy: 99.9319%  Loss: 0.040895\n",
      "Epoch: 377  Val accuracy: 99.9363%  Loss: 0.037786\n",
      "Epoch: 378  Val accuracy: 99.9363%  Loss: 0.038353\n",
      "Epoch: 379  Val accuracy: 99.9363%  Loss: 0.039228\n",
      "Epoch: 380  Val accuracy: 99.9319%  Loss: 0.042645\n",
      "Epoch: 381  Val accuracy: 99.9341%  Loss: 0.038870\n",
      "Epoch: 382  Val accuracy: 99.9385%  Loss: 0.038670\n",
      "Epoch: 383  Val accuracy: 99.9297%  Loss: 0.037186\n",
      "Epoch: 384  Val accuracy: 99.9319%  Loss: 0.038198\n",
      "Epoch: 385  Val accuracy: 99.9363%  Loss: 0.036776\n",
      "Epoch: 386  Val accuracy: 99.9297%  Loss: 0.039544\n",
      "Epoch: 387  Val accuracy: 99.9341%  Loss: 0.040397\n",
      "Epoch: 388  Val accuracy: 99.9209%  Loss: 0.045288\n",
      "Epoch: 389  Val accuracy: 99.9341%  Loss: 0.038254\n",
      "Epoch: 390  Val accuracy: 99.9341%  Loss: 0.038675\n",
      "Epoch: 391  Val accuracy: 99.9275%  Loss: 0.039677\n",
      "Epoch: 392  Val accuracy: 99.9341%  Loss: 0.039894\n",
      "Epoch: 393  Val accuracy: 99.9341%  Loss: 0.039256\n",
      "Epoch: 394  Val accuracy: 99.9341%  Loss: 0.038035\n",
      "Epoch: 395  Val accuracy: 99.9319%  Loss: 0.038733\n",
      "Epoch: 396  Val accuracy: 99.9319%  Loss: 0.037787\n",
      "Epoch: 397  Val accuracy: 99.9341%  Loss: 0.038867\n",
      "Epoch: 398  Val accuracy: 99.9319%  Loss: 0.041323\n",
      "Epoch: 399  Val accuracy: 99.9297%  Loss: 0.040064\n",
      "Epoch: 400  Val accuracy: 99.9253%  Loss: 0.038191\n",
      "Epoch: 401  Val accuracy: 99.9363%  Loss: 0.037923\n",
      "Epoch: 402  Val accuracy: 99.9319%  Loss: 0.039492\n",
      "Epoch: 403  Val accuracy: 99.9319%  Loss: 0.038626\n",
      "Epoch: 404  Val accuracy: 99.9363%  Loss: 0.038550\n",
      "Epoch: 405  Val accuracy: 99.9385%  Loss: 0.036637\n",
      "Epoch: 406  Val accuracy: 99.9319%  Loss: 0.043097\n",
      "Epoch: 407  Val accuracy: 99.9385%  Loss: 0.037920\n",
      "Epoch: 408  Val accuracy: 99.9253%  Loss: 0.039708\n",
      "Epoch: 409  Val accuracy: 99.9297%  Loss: 0.040740\n",
      "Epoch: 410  Val accuracy: 99.9319%  Loss: 0.039131\n",
      "Epoch: 411  Val accuracy: 99.9407%  Loss: 0.038735\n",
      "Epoch: 412  Val accuracy: 99.9319%  Loss: 0.038156\n",
      "Epoch: 413  Val accuracy: 99.9297%  Loss: 0.039235\n",
      "Epoch: 414  Val accuracy: 99.9385%  Loss: 0.039036\n",
      "Epoch: 415  Val accuracy: 99.9319%  Loss: 0.040989\n",
      "Epoch: 416  Val accuracy: 99.9341%  Loss: 0.039167\n",
      "Epoch: 417  Val accuracy: 99.9319%  Loss: 0.038169\n",
      "Epoch: 418  Val accuracy: 99.9363%  Loss: 0.041198\n",
      "Epoch: 419  Val accuracy: 99.9319%  Loss: 0.038254\n",
      "Epoch: 420  Val accuracy: 99.9363%  Loss: 0.037837\n",
      "Epoch: 421  Val accuracy: 99.9297%  Loss: 0.039795\n",
      "Epoch: 422  Val accuracy: 99.9363%  Loss: 0.039062\n",
      "Epoch: 423  Val accuracy: 99.9341%  Loss: 0.037358\n",
      "Epoch: 424  Val accuracy: 99.9297%  Loss: 0.041158\n",
      "Epoch: 425  Val accuracy: 99.9341%  Loss: 0.039272\n",
      "Epoch: 426  Val accuracy: 99.9253%  Loss: 0.039606\n",
      "Epoch: 427  Val accuracy: 99.9297%  Loss: 0.037465\n",
      "Epoch: 428  Val accuracy: 99.9319%  Loss: 0.040373\n",
      "Epoch: 429  Val accuracy: 99.9341%  Loss: 0.039110\n",
      "Epoch: 430  Val accuracy: 99.9319%  Loss: 0.038553\n",
      "Epoch: 431  Val accuracy: 99.9275%  Loss: 0.040012\n",
      "Epoch: 432  Val accuracy: 99.9319%  Loss: 0.040598\n",
      "Epoch: 433  Val accuracy: 99.9385%  Loss: 0.038044\n",
      "Epoch: 434  Val accuracy: 99.9363%  Loss: 0.038429\n",
      "Epoch: 435  Val accuracy: 99.9341%  Loss: 0.037952\n",
      "Epoch: 436  Val accuracy: 99.9319%  Loss: 0.038044\n",
      "Epoch: 437  Val accuracy: 99.9319%  Loss: 0.039807\n",
      "Epoch: 438  Val accuracy: 99.9341%  Loss: 0.037850\n",
      "Epoch: 439  Val accuracy: 99.9385%  Loss: 0.039788\n",
      "Epoch: 440  Val accuracy: 99.9341%  Loss: 0.039604\n",
      "Epoch: 441  Val accuracy: 99.9275%  Loss: 0.038830\n",
      "Epoch: 442  Val accuracy: 99.9341%  Loss: 0.039303\n",
      "Epoch: 443  Val accuracy: 99.9341%  Loss: 0.040607\n",
      "Epoch: 444  Val accuracy: 99.9341%  Loss: 0.039940\n",
      "Epoch: 445  Val accuracy: 99.9363%  Loss: 0.037775\n",
      "Epoch: 446  Val accuracy: 99.9297%  Loss: 0.039229\n",
      "Epoch: 447  Val accuracy: 99.9341%  Loss: 0.040492\n",
      "Epoch: 448  Val accuracy: 99.9319%  Loss: 0.041440\n",
      "Epoch: 449  Val accuracy: 99.9341%  Loss: 0.038655\n",
      "Epoch: 450  Val accuracy: 99.9385%  Loss: 0.038738\n",
      "Epoch: 451  Val accuracy: 99.9363%  Loss: 0.039765\n",
      "Epoch: 452  Val accuracy: 99.9385%  Loss: 0.038681\n",
      "Epoch: 453  Val accuracy: 99.9319%  Loss: 0.040282\n",
      "Epoch: 454  Val accuracy: 99.9363%  Loss: 0.038074\n",
      "Epoch: 455  Val accuracy: 99.9363%  Loss: 0.037805\n",
      "Epoch: 456  Val accuracy: 99.9407%  Loss: 0.036128\n",
      "Epoch: 457  Val accuracy: 99.9319%  Loss: 0.037463\n",
      "Epoch: 458  Val accuracy: 99.9319%  Loss: 0.038342\n",
      "Epoch: 459  Val accuracy: 99.9363%  Loss: 0.038236\n",
      "Epoch: 460  Val accuracy: 99.9319%  Loss: 0.041393\n",
      "Epoch: 461  Val accuracy: 99.9341%  Loss: 0.038452\n",
      "Epoch: 462  Val accuracy: 99.9319%  Loss: 0.038457\n",
      "Epoch: 463  Val accuracy: 99.9297%  Loss: 0.039029\n",
      "Epoch: 464  Val accuracy: 99.9297%  Loss: 0.039444\n",
      "Epoch: 465  Val accuracy: 99.9275%  Loss: 0.038095\n",
      "Epoch: 466  Val accuracy: 99.9385%  Loss: 0.038377\n",
      "Epoch: 467  Val accuracy: 99.9319%  Loss: 0.038690\n",
      "Epoch: 468  Val accuracy: 99.9297%  Loss: 0.037466\n",
      "Epoch: 469  Val accuracy: 99.9231%  Loss: 0.037059\n",
      "Epoch: 470  Val accuracy: 99.9341%  Loss: 0.039408\n",
      "Epoch: 471  Val accuracy: 99.9363%  Loss: 0.038544\n",
      "Epoch: 472  Val accuracy: 99.9275%  Loss: 0.039285\n",
      "Epoch: 473  Val accuracy: 99.9363%  Loss: 0.038088\n",
      "Epoch: 474  Val accuracy: 99.9341%  Loss: 0.039397\n",
      "Epoch: 475  Val accuracy: 99.9341%  Loss: 0.039281\n",
      "Epoch: 476  Val accuracy: 99.9341%  Loss: 0.038794\n",
      "Epoch: 477  Val accuracy: 99.9319%  Loss: 0.037080\n",
      "Epoch: 478  Val accuracy: 99.9385%  Loss: 0.038396\n",
      "Epoch: 479  Val accuracy: 99.9385%  Loss: 0.039351\n",
      "Epoch: 480  Val accuracy: 99.9341%  Loss: 0.041263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 481  Val accuracy: 99.9363%  Loss: 0.039224\n",
      "Epoch: 482  Val accuracy: 99.9363%  Loss: 0.038980\n",
      "Epoch: 483  Val accuracy: 99.9385%  Loss: 0.038611\n",
      "Epoch: 484  Val accuracy: 99.9363%  Loss: 0.039284\n",
      "Epoch: 485  Val accuracy: 99.9319%  Loss: 0.040248\n",
      "Epoch: 486  Val accuracy: 99.9341%  Loss: 0.038343\n",
      "Epoch: 487  Val accuracy: 99.9363%  Loss: 0.038107\n",
      "Epoch: 488  Val accuracy: 99.9275%  Loss: 0.037566\n",
      "Epoch: 489  Val accuracy: 99.9319%  Loss: 0.040605\n",
      "Epoch: 490  Val accuracy: 99.9319%  Loss: 0.039858\n",
      "Epoch: 491  Val accuracy: 99.9385%  Loss: 0.036680\n",
      "Epoch: 492  Val accuracy: 99.9341%  Loss: 0.037393\n",
      "Epoch: 493  Val accuracy: 99.9341%  Loss: 0.038399\n",
      "Epoch: 494  Val accuracy: 99.9319%  Loss: 0.037795\n",
      "Epoch: 495  Val accuracy: 99.9319%  Loss: 0.039772\n",
      "Epoch: 496  Val accuracy: 99.9275%  Loss: 0.039098\n",
      "Epoch: 497  Val accuracy: 99.9341%  Loss: 0.037530\n",
      "Epoch: 498  Val accuracy: 99.9275%  Loss: 0.038658\n",
      "Epoch: 499  Val accuracy: 99.9407%  Loss: 0.037146\n",
      "Epoch: 500  Val accuracy: 99.9363%  Loss: 0.037932\n",
      "Epoch: 501  Val accuracy: 99.9319%  Loss: 0.038451\n",
      "Epoch: 502  Val accuracy: 99.9341%  Loss: 0.039432\n",
      "Epoch: 503  Val accuracy: 99.9319%  Loss: 0.039021\n",
      "Epoch: 504  Val accuracy: 99.9341%  Loss: 0.038687\n",
      "Epoch: 505  Val accuracy: 99.9363%  Loss: 0.037217\n",
      "Epoch: 506  Val accuracy: 99.9231%  Loss: 0.039591\n",
      "Epoch: 507  Val accuracy: 99.9363%  Loss: 0.038253\n",
      "Epoch: 508  Val accuracy: 99.9275%  Loss: 0.039303\n",
      "Epoch: 509  Val accuracy: 99.9341%  Loss: 0.039169\n",
      "Epoch: 510  Val accuracy: 99.9341%  Loss: 0.037344\n",
      "Epoch: 511  Val accuracy: 99.9319%  Loss: 0.039235\n",
      "Epoch: 512  Val accuracy: 99.9385%  Loss: 0.039552\n",
      "Epoch: 513  Val accuracy: 99.9363%  Loss: 0.038203\n",
      "Epoch: 514  Val accuracy: 99.9297%  Loss: 0.041209\n",
      "Epoch: 515  Val accuracy: 99.9363%  Loss: 0.037387\n",
      "Epoch: 516  Val accuracy: 99.9341%  Loss: 0.036373\n",
      "Epoch: 517  Val accuracy: 99.9341%  Loss: 0.039587\n",
      "Epoch: 518  Val accuracy: 99.9341%  Loss: 0.037519\n",
      "Epoch: 519  Val accuracy: 99.9319%  Loss: 0.039419\n",
      "Epoch: 520  Val accuracy: 99.9341%  Loss: 0.040242\n",
      "Epoch: 521  Val accuracy: 99.9341%  Loss: 0.041188\n",
      "Epoch: 522  Val accuracy: 99.9341%  Loss: 0.040350\n",
      "Epoch: 523  Val accuracy: 99.9341%  Loss: 0.039701\n",
      "Epoch: 524  Val accuracy: 99.9363%  Loss: 0.038884\n",
      "Epoch: 525  Val accuracy: 99.9385%  Loss: 0.037726\n",
      "Epoch: 526  Val accuracy: 99.9407%  Loss: 0.037124\n",
      "Epoch: 527  Val accuracy: 99.9341%  Loss: 0.039616\n",
      "Epoch: 528  Val accuracy: 99.9341%  Loss: 0.037774\n",
      "Epoch: 529  Val accuracy: 99.9319%  Loss: 0.038484\n",
      "Epoch: 530  Val accuracy: 99.9319%  Loss: 0.038911\n",
      "Epoch: 531  Val accuracy: 99.9341%  Loss: 0.037901\n",
      "Epoch: 532  Val accuracy: 99.9341%  Loss: 0.040121\n",
      "Epoch: 533  Val accuracy: 99.9341%  Loss: 0.040424\n",
      "Epoch: 534  Val accuracy: 99.9363%  Loss: 0.038132\n",
      "Epoch: 535  Val accuracy: 99.9275%  Loss: 0.037042\n",
      "Epoch: 536  Val accuracy: 99.9363%  Loss: 0.038510\n",
      "Epoch: 537  Val accuracy: 99.9319%  Loss: 0.038485\n",
      "Epoch: 538  Val accuracy: 99.9253%  Loss: 0.040221\n",
      "Epoch: 539  Val accuracy: 99.9341%  Loss: 0.038169\n",
      "Epoch: 540  Val accuracy: 99.9319%  Loss: 0.040343\n",
      "Epoch: 541  Val accuracy: 99.9253%  Loss: 0.038518\n",
      "Epoch: 542  Val accuracy: 99.9319%  Loss: 0.039614\n",
      "Epoch: 543  Val accuracy: 99.9341%  Loss: 0.036653\n",
      "Epoch: 544  Val accuracy: 99.9341%  Loss: 0.036844\n",
      "Epoch: 545  Val accuracy: 99.9319%  Loss: 0.039509\n",
      "Epoch: 546  Val accuracy: 99.9363%  Loss: 0.036330\n",
      "Epoch: 547  Val accuracy: 99.9319%  Loss: 0.039908\n",
      "Epoch: 548  Val accuracy: 99.9319%  Loss: 0.039362\n",
      "Epoch: 549  Val accuracy: 99.9363%  Loss: 0.038644\n",
      "Epoch: 550  Val accuracy: 99.9319%  Loss: 0.039365\n",
      "Epoch: 551  Val accuracy: 99.9319%  Loss: 0.037487\n",
      "Epoch: 552  Val accuracy: 99.9341%  Loss: 0.038184\n",
      "Epoch: 553  Val accuracy: 99.9363%  Loss: 0.036978\n",
      "Epoch: 554  Val accuracy: 99.9319%  Loss: 0.036061\n",
      "Epoch: 555  Val accuracy: 99.9319%  Loss: 0.040160\n",
      "Epoch: 556  Val accuracy: 99.9231%  Loss: 0.038919\n",
      "Epoch: 557  Val accuracy: 99.9363%  Loss: 0.038076\n",
      "Epoch: 558  Val accuracy: 99.9275%  Loss: 0.039738\n",
      "Epoch: 559  Val accuracy: 99.9363%  Loss: 0.039389\n",
      "Epoch: 560  Val accuracy: 99.9341%  Loss: 0.038497\n",
      "Epoch: 561  Val accuracy: 99.9341%  Loss: 0.039120\n",
      "Epoch: 562  Val accuracy: 99.9385%  Loss: 0.038248\n",
      "Epoch: 563  Val accuracy: 99.9341%  Loss: 0.039591\n",
      "Epoch: 564  Val accuracy: 99.9341%  Loss: 0.041794\n",
      "Epoch: 565  Val accuracy: 99.9341%  Loss: 0.037766\n",
      "Epoch: 566  Val accuracy: 99.9341%  Loss: 0.039389\n",
      "Epoch: 567  Val accuracy: 99.9319%  Loss: 0.039665\n",
      "Epoch: 568  Val accuracy: 99.9275%  Loss: 0.038736\n",
      "Epoch: 569  Val accuracy: 99.9429%  Loss: 0.038806\n",
      "Epoch: 570  Val accuracy: 99.9341%  Loss: 0.037821\n",
      "Epoch: 571  Val accuracy: 99.9297%  Loss: 0.038243\n",
      "Epoch: 572  Val accuracy: 99.9341%  Loss: 0.038406\n",
      "Epoch: 573  Val accuracy: 99.9341%  Loss: 0.038901\n",
      "Epoch: 574  Val accuracy: 99.9341%  Loss: 0.039803\n",
      "Epoch: 575  Val accuracy: 99.9319%  Loss: 0.039455\n",
      "Epoch: 576  Val accuracy: 99.9341%  Loss: 0.040567\n",
      "Epoch: 577  Val accuracy: 99.9275%  Loss: 0.040628\n",
      "Epoch: 578  Val accuracy: 99.9319%  Loss: 0.039176\n",
      "Epoch: 579  Val accuracy: 99.9297%  Loss: 0.036533\n",
      "Epoch: 580  Val accuracy: 99.9319%  Loss: 0.041082\n",
      "Epoch: 581  Val accuracy: 99.9319%  Loss: 0.036550\n",
      "Epoch: 582  Val accuracy: 99.9341%  Loss: 0.041534\n",
      "Epoch: 583  Val accuracy: 99.9297%  Loss: 0.040663\n",
      "Epoch: 584  Val accuracy: 99.9341%  Loss: 0.039557\n",
      "Epoch: 585  Val accuracy: 99.9319%  Loss: 0.040854\n",
      "Epoch: 586  Val accuracy: 99.9385%  Loss: 0.037411\n",
      "Epoch: 587  Val accuracy: 99.9297%  Loss: 0.039765\n",
      "Epoch: 588  Val accuracy: 99.9341%  Loss: 0.039844\n",
      "Epoch: 589  Val accuracy: 99.9341%  Loss: 0.037334\n",
      "Epoch: 590  Val accuracy: 99.9319%  Loss: 0.036492\n",
      "Epoch: 591  Val accuracy: 99.9341%  Loss: 0.037769\n",
      "Epoch: 592  Val accuracy: 99.9363%  Loss: 0.039164\n",
      "Epoch: 593  Val accuracy: 99.9341%  Loss: 0.039459\n",
      "Epoch: 594  Val accuracy: 99.9319%  Loss: 0.042045\n",
      "Epoch: 595  Val accuracy: 99.9363%  Loss: 0.038540\n",
      "Epoch: 596  Val accuracy: 99.9385%  Loss: 0.039269\n",
      "Epoch: 597  Val accuracy: 99.9385%  Loss: 0.038983\n",
      "Epoch: 598  Val accuracy: 99.9319%  Loss: 0.037807\n",
      "Epoch: 599  Val accuracy: 99.9275%  Loss: 0.038449\n",
      "Epoch: 600  Val accuracy: 99.9341%  Loss: 0.038084\n",
      "Epoch: 601  Val accuracy: 99.9319%  Loss: 0.039672\n",
      "Epoch: 602  Val accuracy: 99.9363%  Loss: 0.038409\n",
      "Epoch: 603  Val accuracy: 99.9341%  Loss: 0.038665\n",
      "Epoch: 604  Val accuracy: 99.9341%  Loss: 0.040282\n",
      "Epoch: 605  Val accuracy: 99.9319%  Loss: 0.039738\n",
      "Epoch: 606  Val accuracy: 99.9319%  Loss: 0.038056\n",
      "Epoch: 607  Val accuracy: 99.9341%  Loss: 0.037641\n",
      "Epoch: 608  Val accuracy: 99.9341%  Loss: 0.037747\n",
      "Epoch: 609  Val accuracy: 99.9363%  Loss: 0.037873\n",
      "Epoch: 610  Val accuracy: 99.9407%  Loss: 0.037219\n",
      "Epoch: 611  Val accuracy: 99.9297%  Loss: 0.040022\n",
      "Epoch: 612  Val accuracy: 99.9341%  Loss: 0.037988     \n",
      "Epoch: 613  Val accuracy: 99.9341%  Loss: 0.038513\n",
      "Epoch: 614  Val accuracy: 99.9319%  Loss: 0.039023\n",
      "Epoch: 615  Val accuracy: 99.9319%  Loss: 0.037990\n",
      "Epoch: 616  Val accuracy: 99.9253%  Loss: 0.037363\n",
      "Epoch: 617  Val accuracy: 99.9319%  Loss: 0.040338\n",
      "Epoch: 618  Val accuracy: 99.9341%  Loss: 0.037451\n",
      "Epoch: 619  Val accuracy: 99.9363%  Loss: 0.037937\n",
      "Epoch: 620  Val accuracy: 99.9363%  Loss: 0.038644\n",
      "Epoch: 621  Val accuracy: 99.9363%  Loss: 0.037866\n",
      "Epoch: 622  Val accuracy: 99.9319%  Loss: 0.039831\n",
      "Epoch: 623  Val accuracy: 99.9319%  Loss: 0.039249\n",
      "Epoch: 624  Val accuracy: 99.9297%  Loss: 0.040193\n",
      "Epoch: 625  Val accuracy: 99.9253%  Loss: 0.039093\n",
      "Epoch: 626  Val accuracy: 99.9341%  Loss: 0.037931\n",
      "Epoch: 627  Val accuracy: 99.9275%  Loss: 0.038482\n",
      "Epoch: 628  Val accuracy: 99.9363%  Loss: 0.038674\n",
      "Epoch: 629  Val accuracy: 99.9363%  Loss: 0.038379\n",
      "Epoch: 630  Val accuracy: 99.9341%  Loss: 0.038317\n",
      "Epoch: 631  Val accuracy: 99.9363%  Loss: 0.039846\n",
      "Epoch: 632  Val accuracy: 99.9407%  Loss: 0.036861\n",
      "Epoch: 633  Val accuracy: 99.9319%  Loss: 0.040960\n",
      "Epoch: 634  Val accuracy: 99.9319%  Loss: 0.038273\n",
      "Epoch: 635  Val accuracy: 99.9385%  Loss: 0.038310\n",
      "Epoch: 636  Val accuracy: 99.9341%  Loss: 0.038567\n",
      "Epoch: 637  Val accuracy: 99.9385%  Loss: 0.037168\n",
      "Epoch: 638  Val accuracy: 99.9363%  Loss: 0.039435\n",
      "Epoch: 639  Val accuracy: 99.9341%  Loss: 0.037644\n",
      "Epoch: 640  Val accuracy: 99.9319%  Loss: 0.041601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 641  Val accuracy: 99.9297%  Loss: 0.039444\n",
      "Epoch: 642  Val accuracy: 99.9319%  Loss: 0.038456\n",
      "Epoch: 643  Val accuracy: 99.9275%  Loss: 0.039294\n",
      "Epoch: 644  Val accuracy: 99.9385%  Loss: 0.036837\n",
      "Epoch: 645  Val accuracy: 99.9363%  Loss: 0.037664\n",
      "Epoch: 646  Val accuracy: 99.9319%  Loss: 0.037914\n",
      "Epoch: 647  Val accuracy: 99.9363%  Loss: 0.040378\n",
      "Epoch: 648  Val accuracy: 99.9341%  Loss: 0.037630\n",
      "Epoch: 649  Val accuracy: 99.9275%  Loss: 0.038450\n",
      "Epoch: 650  Val accuracy: 99.9319%  Loss: 0.038251\n",
      "Epoch: 651  Val accuracy: 99.9363%  Loss: 0.037828\n",
      "Epoch: 652  Val accuracy: 99.9319%  Loss: 0.038770\n",
      "Epoch: 653  Val accuracy: 99.9385%  Loss: 0.038123\n",
      "Epoch: 654  Val accuracy: 99.9363%  Loss: 0.037950\n",
      "Epoch: 655  Val accuracy: 99.9341%  Loss: 0.038017\n",
      "Epoch: 656  Val accuracy: 99.9341%  Loss: 0.041948\n",
      "Epoch: 657  Val accuracy: 99.9363%  Loss: 0.042409\n",
      "Epoch: 658  Val accuracy: 99.9319%  Loss: 0.039877\n",
      "Epoch: 659  Val accuracy: 99.9319%  Loss: 0.038254\n",
      "Epoch: 660  Val accuracy: 99.9341%  Loss: 0.036942\n",
      "Epoch: 661  Val accuracy: 99.9319%  Loss: 0.040520\n",
      "Epoch: 662  Val accuracy: 99.9363%  Loss: 0.037853\n",
      "Epoch: 663  Val accuracy: 99.9341%  Loss: 0.038135\n",
      "Epoch: 664  Val accuracy: 99.9341%  Loss: 0.037802\n",
      "Epoch: 665  Val accuracy: 99.9319%  Loss: 0.039531\n",
      "Epoch: 666  Val accuracy: 99.9363%  Loss: 0.036586\n",
      "Epoch: 667  Val accuracy: 99.9363%  Loss: 0.038174\n",
      "Epoch: 668  Val accuracy: 99.9363%  Loss: 0.037699\n",
      "Epoch: 669  Val accuracy: 99.9429%  Loss: 0.038365\n",
      "Epoch: 670  Val accuracy: 99.9341%  Loss: 0.039815\n",
      "Epoch: 671  Val accuracy: 99.9319%  Loss: 0.041187\n",
      "Epoch: 672  Val accuracy: 99.9385%  Loss: 0.038090\n",
      "Epoch: 673  Val accuracy: 99.9341%  Loss: 0.041032\n",
      "Epoch: 674  Val accuracy: 99.9341%  Loss: 0.037024\n",
      "Epoch: 675  Val accuracy: 99.9319%  Loss: 0.039618\n",
      "Epoch: 676  Val accuracy: 99.9341%  Loss: 0.038210\n",
      "Epoch: 677  Val accuracy: 99.9341%  Loss: 0.037556\n",
      "Epoch: 678  Val accuracy: 99.9363%  Loss: 0.036489\n",
      "Epoch: 679  Val accuracy: 99.9363%  Loss: 0.037967\n",
      "Epoch: 680  Val accuracy: 99.9363%  Loss: 0.038884\n",
      "Epoch: 681  Val accuracy: 99.9341%  Loss: 0.038956\n",
      "Epoch: 682  Val accuracy: 99.9385%  Loss: 0.038506\n",
      "Epoch: 683  Val accuracy: 99.9297%  Loss: 0.039674\n",
      "Epoch: 684  Val accuracy: 99.9385%  Loss: 0.040176\n",
      "Epoch: 685  Val accuracy: 99.9341%  Loss: 0.039943\n",
      "Epoch: 686  Val accuracy: 99.9341%  Loss: 0.040328\n",
      "Epoch: 687  Val accuracy: 99.9319%  Loss: 0.053103\n",
      "Epoch: 688  Val accuracy: 99.9297%  Loss: 0.039188\n",
      "Epoch: 689  Val accuracy: 99.9319%  Loss: 0.038045\n",
      "Epoch: 690  Val accuracy: 99.9341%  Loss: 0.038128\n",
      "Epoch: 691  Val accuracy: 99.9275%  Loss: 0.038954\n",
      "Epoch: 692  Val accuracy: 99.9341%  Loss: 0.038648\n",
      "Epoch: 693  Val accuracy: 99.9319%  Loss: 0.037350\n",
      "Epoch: 694  Val accuracy: 99.9341%  Loss: 0.040269\n",
      "Epoch: 695  Val accuracy: 99.9319%  Loss: 0.040138\n",
      "Epoch: 696  Val accuracy: 99.9363%  Loss: 0.038979\n",
      "Epoch: 697  Val accuracy: 99.9297%  Loss: 0.038129\n",
      "Epoch: 698  Val accuracy: 99.9385%  Loss: 0.038558\n",
      "Epoch: 699  Val accuracy: 99.9319%  Loss: 0.041269\n",
      "Epoch: 700  Val accuracy: 99.9297%  Loss: 0.038406\n",
      "Epoch: 701  Val accuracy: 99.9341%  Loss: 0.039388\n",
      "Epoch: 702  Val accuracy: 99.9363%  Loss: 0.039149\n",
      "Epoch: 703  Val accuracy: 99.9385%  Loss: 0.038317\n",
      "Epoch: 704  Val accuracy: 99.9385%  Loss: 0.036433\n",
      "Epoch: 705  Val accuracy: 99.9385%  Loss: 0.037766\n",
      "Epoch: 706  Val accuracy: 99.9363%  Loss: 0.036991\n",
      "Epoch: 707  Val accuracy: 99.9319%  Loss: 0.038257\n",
      "Epoch: 708  Val accuracy: 99.9319%  Loss: 0.042380\n",
      "Epoch: 709  Val accuracy: 99.9319%  Loss: 0.038163\n",
      "Epoch: 710  Val accuracy: 99.9319%  Loss: 0.037842\n",
      "Epoch: 711  Val accuracy: 99.9341%  Loss: 0.038503\n",
      "Epoch: 712  Val accuracy: 99.9385%  Loss: 0.040345\n",
      "Epoch: 713  Val accuracy: 99.9363%  Loss: 0.038217\n",
      "Epoch: 714  Val accuracy: 99.9407%  Loss: 0.037814\n",
      "Epoch: 715  Val accuracy: 99.9341%  Loss: 0.038019\n",
      "Epoch: 716  Val accuracy: 99.9319%  Loss: 0.039211\n",
      "Epoch: 717  Val accuracy: 99.9319%  Loss: 0.038415\n",
      "Epoch: 718  Val accuracy: 99.9319%  Loss: 0.038185\n",
      "Epoch: 719  Val accuracy: 99.9319%  Loss: 0.039635\n",
      "Epoch: 720  Val accuracy: 99.9319%  Loss: 0.040408\n",
      "Epoch: 721  Val accuracy: 99.9319%  Loss: 0.038313\n",
      "Epoch: 722  Val accuracy: 99.9319%  Loss: 0.037875\n",
      "Epoch: 723  Val accuracy: 99.9385%  Loss: 0.037837\n",
      "Epoch: 724  Val accuracy: 99.9341%  Loss: 0.038775\n",
      "Epoch: 725  Val accuracy: 99.9363%  Loss: 0.037593\n",
      "Epoch: 726  Val accuracy: 99.9319%  Loss: 0.039354\n",
      "Epoch: 727  Val accuracy: 99.9341%  Loss: 0.039556\n",
      "Epoch: 728  Val accuracy: 99.9319%  Loss: 0.039489\n",
      "Epoch: 729  Val accuracy: 99.9385%  Loss: 0.036935\n",
      "Epoch: 730  Val accuracy: 99.9363%  Loss: 0.039570\n",
      "Epoch: 731  Val accuracy: 99.9363%  Loss: 0.038720\n",
      "Epoch: 732  Val accuracy: 99.9363%  Loss: 0.039842\n",
      "Epoch: 733  Val accuracy: 99.9385%  Loss: 0.037449\n",
      "Epoch: 734  Val accuracy: 99.9363%  Loss: 0.038541\n",
      "Epoch: 735  Val accuracy: 99.9385%  Loss: 0.038638\n",
      "Epoch: 736  Val accuracy: 99.9363%  Loss: 0.038396\n",
      "Epoch: 737  Val accuracy: 99.9363%  Loss: 0.038834\n",
      "Epoch: 738  Val accuracy: 99.9297%  Loss: 0.040333\n",
      "Epoch: 739  Val accuracy: 99.9341%  Loss: 0.038272\n",
      "Epoch: 740  Val accuracy: 99.9341%  Loss: 0.039271\n",
      "Epoch: 741  Val accuracy: 99.9363%  Loss: 0.037593\n",
      "Epoch: 742  Val accuracy: 99.9363%  Loss: 0.039232\n",
      "Epoch: 743  Val accuracy: 99.9319%  Loss: 0.041688\n",
      "Epoch: 744  Val accuracy: 99.9319%  Loss: 0.038594\n",
      "Epoch: 745  Val accuracy: 99.9341%  Loss: 0.040009\n",
      "Epoch: 746  Val accuracy: 99.9341%  Loss: 0.038889\n",
      "Epoch: 747  Val accuracy: 99.9341%  Loss: 0.039147\n",
      "Epoch: 748  Val accuracy: 99.9341%  Loss: 0.040018\n",
      "Epoch: 749  Val accuracy: 99.9341%  Loss: 0.040476\n",
      "Epoch: 750  Val accuracy: 99.9341%  Loss: 0.040433\n",
      "Epoch: 751  Val accuracy: 99.9363%  Loss: 0.040488\n",
      "Epoch: 752  Val accuracy: 99.9363%  Loss: 0.039765\n",
      "Epoch: 753  Val accuracy: 99.9341%  Loss: 0.040335\n",
      "Epoch: 754  Val accuracy: 99.9363%  Loss: 0.039442\n",
      "Epoch: 755  Val accuracy: 99.9341%  Loss: 0.038323\n",
      "Epoch: 756  Val accuracy: 99.9385%  Loss: 0.040444\n",
      "Epoch: 757  Val accuracy: 99.9341%  Loss: 0.039672\n",
      "Epoch: 758  Val accuracy: 99.9275%  Loss: 0.041931\n",
      "Epoch: 759  Val accuracy: 99.9363%  Loss: 0.039607\n",
      "Epoch: 760  Val accuracy: 99.9341%  Loss: 0.039081\n",
      "Epoch: 761  Val accuracy: 99.9363%  Loss: 0.038872\n",
      "Epoch: 762  Val accuracy: 99.9363%  Loss: 0.039181\n",
      "Epoch: 763  Val accuracy: 99.9363%  Loss: 0.037377\n",
      "Epoch: 764  Val accuracy: 99.9429%  Loss: 0.038339\n",
      "Epoch: 765  Val accuracy: 99.9363%  Loss: 0.039589\n",
      "Epoch: 766  Val accuracy: 99.9363%  Loss: 0.037523\n",
      "Epoch: 767  Val accuracy: 99.9407%  Loss: 0.038653\n",
      "Epoch: 768  Val accuracy: 99.9385%  Loss: 0.038201\n",
      "Epoch: 769  Val accuracy: 99.9363%  Loss: 0.038898\n",
      "Epoch: 770  Val accuracy: 99.9319%  Loss: 0.038597\n",
      "Epoch: 771  Val accuracy: 99.9363%  Loss: 0.038502\n",
      "Epoch: 772  Val accuracy: 99.9341%  Loss: 0.038511\n",
      "Epoch: 773  Val accuracy: 99.9341%  Loss: 0.039733\n",
      "Epoch: 774  Val accuracy: 99.9319%  Loss: 0.040583\n",
      "Epoch: 775  Val accuracy: 99.9341%  Loss: 0.039984\n",
      "Epoch: 776  Val accuracy: 99.9363%  Loss: 0.038215\n",
      "Epoch: 777  Val accuracy: 99.9407%  Loss: 0.038903\n",
      "Epoch: 778  Val accuracy: 99.9319%  Loss: 0.038287\n",
      "Epoch: 779  Val accuracy: 99.9363%  Loss: 0.037863\n",
      "Epoch: 780  Val accuracy: 99.9385%  Loss: 0.040926\n",
      "Epoch: 781  Val accuracy: 99.9385%  Loss: 0.039119\n",
      "Epoch: 782  Val accuracy: 99.9363%  Loss: 0.040156\n",
      "Epoch: 783  Val accuracy: 99.9341%  Loss: 0.039160\n",
      "Epoch: 784  Val accuracy: 99.9275%  Loss: 0.039597\n",
      "Epoch: 785  Val accuracy: 99.9385%  Loss: 0.038684\n",
      "Epoch: 786  Val accuracy: 99.9341%  Loss: 0.039052\n",
      "Epoch: 787  Val accuracy: 99.9385%  Loss: 0.039893\n",
      "Epoch: 788  Val accuracy: 99.9363%  Loss: 0.040204\n",
      "Epoch: 789  Val accuracy: 99.9363%  Loss: 0.040071\n",
      "Epoch: 790  Val accuracy: 99.9385%  Loss: 0.040339\n",
      "Epoch: 791  Val accuracy: 99.9407%  Loss: 0.043471\n",
      "Epoch: 792  Val accuracy: 99.9297%  Loss: 0.041574\n",
      "Epoch: 793  Val accuracy: 99.9363%  Loss: 0.040287\n",
      "Epoch: 794  Val accuracy: 99.9363%  Loss: 0.038210\n",
      "Epoch: 795  Val accuracy: 99.9341%  Loss: 0.040094\n",
      "Epoch: 796  Val accuracy: 99.9341%  Loss: 0.040313\n",
      "Epoch: 797  Val accuracy: 99.9363%  Loss: 0.038621\n",
      "Epoch: 798  Val accuracy: 99.9319%  Loss: 0.040256\n",
      "Epoch: 799  Val accuracy: 99.9341%  Loss: 0.038078\n",
      "Epoch: 800  Val accuracy: 99.9363%  Loss: 0.038864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 801  Val accuracy: 99.9407%  Loss: 0.039491\n",
      "Epoch: 802  Val accuracy: 99.9363%  Loss: 0.039592\n",
      "Epoch: 803  Val accuracy: 99.9297%  Loss: 0.042099\n",
      "Epoch: 804  Val accuracy: 99.9341%  Loss: 0.038291\n",
      "Epoch: 805  Val accuracy: 99.9297%  Loss: 0.037212\n",
      "Epoch: 806  Val accuracy: 99.9407%  Loss: 0.037920\n",
      "Epoch: 807  Val accuracy: 99.9319%  Loss: 0.038807\n",
      "Epoch: 808  Val accuracy: 99.9363%  Loss: 0.039641\n",
      "Epoch: 809  Val accuracy: 99.9341%  Loss: 0.038180\n",
      "Epoch: 810  Val accuracy: 99.9385%  Loss: 0.039144\n",
      "Epoch: 811  Val accuracy: 99.9363%  Loss: 0.039216\n",
      "Epoch: 812  Val accuracy: 99.9385%  Loss: 0.040003\n",
      "Epoch: 813  Val accuracy: 99.9341%  Loss: 0.040175\n",
      "Epoch: 814  Val accuracy: 99.9341%  Loss: 0.039638\n",
      "Epoch: 815  Val accuracy: 99.9363%  Loss: 0.039777\n",
      "Epoch: 816  Val accuracy: 99.9385%  Loss: 0.039978\n",
      "Epoch: 817  Val accuracy: 99.9341%  Loss: 0.047559\n",
      "Epoch: 818  Val accuracy: 99.9385%  Loss: 0.037374\n",
      "Epoch: 819  Val accuracy: 99.9341%  Loss: 0.039890\n",
      "Epoch: 820  Val accuracy: 99.9363%  Loss: 0.038126\n",
      "Epoch: 821  Val accuracy: 99.9363%  Loss: 0.038143\n",
      "Epoch: 822  Val accuracy: 99.9319%  Loss: 0.038739\n",
      "Epoch: 823  Val accuracy: 99.9341%  Loss: 0.039278\n",
      "Epoch: 824  Val accuracy: 99.9407%  Loss: 0.038498\n",
      "Epoch: 825  Val accuracy: 99.9385%  Loss: 0.039783\n",
      "Epoch: 826  Val accuracy: 99.9385%  Loss: 0.040505\n",
      "Epoch: 827  Val accuracy: 99.9341%  Loss: 0.039572\n",
      "Epoch: 828  Val accuracy: 99.9341%  Loss: 0.041199\n",
      "Epoch: 829  Val accuracy: 99.9385%  Loss: 0.038265\n",
      "Epoch: 830  Val accuracy: 99.9385%  Loss: 0.039329\n",
      "Epoch: 831  Val accuracy: 99.9363%  Loss: 0.039317\n",
      "Epoch: 832  Val accuracy: 99.9385%  Loss: 0.039289\n",
      "Epoch: 833  Val accuracy: 99.9319%  Loss: 0.039769\n",
      "Epoch: 834  Val accuracy: 99.9319%  Loss: 0.039480\n",
      "Epoch: 835  Val accuracy: 99.9363%  Loss: 0.039592\n",
      "Epoch: 836  Val accuracy: 99.9319%  Loss: 0.038743\n",
      "Epoch: 837  Val accuracy: 99.9385%  Loss: 0.040005\n",
      "Epoch: 838  Val accuracy: 99.9363%  Loss: 0.037821\n",
      "Epoch: 839  Val accuracy: 99.9385%  Loss: 0.039239\n",
      "Epoch: 840  Val accuracy: 99.9363%  Loss: 0.038275\n",
      "Epoch: 841  Val accuracy: 99.9319%  Loss: 0.039015\n",
      "Epoch: 842  Val accuracy: 99.9297%  Loss: 0.038598\n",
      "Epoch: 843  Val accuracy: 99.9363%  Loss: 0.038029\n",
      "Epoch: 844  Val accuracy: 99.9385%  Loss: 0.039708\n",
      "Epoch: 845  Val accuracy: 99.9363%  Loss: 0.039137\n",
      "Epoch: 846  Val accuracy: 99.9275%  Loss: 0.038873\n",
      "Epoch: 847  Val accuracy: 99.9385%  Loss: 0.039294\n",
      "Epoch: 848  Val accuracy: 99.9341%  Loss: 0.040784\n",
      "Epoch: 849  Val accuracy: 99.9319%  Loss: 0.040246\n",
      "Epoch: 850  Val accuracy: 99.9253%  Loss: 0.040075\n",
      "Epoch: 851  Val accuracy: 99.9363%  Loss: 0.038841\n",
      "Epoch: 852  Val accuracy: 99.9363%  Loss: 0.037779\n",
      "Epoch: 853  Val accuracy: 99.9385%  Loss: 0.038546\n",
      "Epoch: 854  Val accuracy: 99.9275%  Loss: 0.039747\n",
      "Epoch: 855  Val accuracy: 99.9253%  Loss: 0.043947\n",
      "Epoch: 856  Val accuracy: 99.9319%  Loss: 0.037565\n",
      "Epoch: 857  Val accuracy: 99.9363%  Loss: 0.038681\n",
      "Epoch: 858  Val accuracy: 99.9407%  Loss: 0.039228\n",
      "Epoch: 859  Val accuracy: 99.9385%  Loss: 0.038887\n",
      "Epoch: 860  Val accuracy: 99.9363%  Loss: 0.039610\n",
      "Epoch: 861  Val accuracy: 99.9319%  Loss: 0.039844\n",
      "Epoch: 862  Val accuracy: 99.9341%  Loss: 0.039652\n",
      "Epoch: 863  Val accuracy: 99.9363%  Loss: 0.040566\n",
      "Epoch: 864  Val accuracy: 99.9341%  Loss: 0.039571\n",
      "Epoch: 865  Val accuracy: 99.9319%  Loss: 0.041108\n",
      "Epoch: 866  Val accuracy: 99.9407%  Loss: 0.039644\n",
      "Epoch: 867  Val accuracy: 99.9319%  Loss: 0.040828\n",
      "Epoch: 868  Val accuracy: 99.9341%  Loss: 0.037866\n",
      "Epoch: 869  Val accuracy: 99.9341%  Loss: 0.037563\n",
      "Epoch: 870  Val accuracy: 99.9341%  Loss: 0.036997\n",
      "Epoch: 871  Val accuracy: 99.9341%  Loss: 0.044347\n",
      "Epoch: 872  Val accuracy: 99.9319%  Loss: 0.040887\n",
      "Epoch: 873  Val accuracy: 99.9385%  Loss: 0.037297\n",
      "Epoch: 874  Val accuracy: 99.9319%  Loss: 0.039521\n",
      "Epoch: 875  Val accuracy: 99.9341%  Loss: 0.040122\n",
      "Epoch: 876  Val accuracy: 99.9363%  Loss: 0.039163\n",
      "Epoch: 877  Val accuracy: 99.9385%  Loss: 0.038408\n",
      "Epoch: 878  Val accuracy: 99.9407%  Loss: 0.039717\n",
      "Epoch: 879  Val accuracy: 99.9385%  Loss: 0.039692\n",
      "Epoch: 880  Val accuracy: 99.9341%  Loss: 0.042706\n",
      "Epoch: 881  Val accuracy: 99.9363%  Loss: 0.038378\n",
      "Epoch: 882  Val accuracy: 99.9385%  Loss: 0.038475\n",
      "Epoch: 883  Val accuracy: 99.9385%  Loss: 0.039368\n",
      "Epoch: 884  Val accuracy: 99.9407%  Loss: 0.039553\n",
      "Epoch: 885  Val accuracy: 99.9385%  Loss: 0.040137\n",
      "Epoch: 886  Val accuracy: 99.9363%  Loss: 0.040312\n",
      "Epoch: 887  Val accuracy: 99.9341%  Loss: 0.041163\n",
      "Epoch: 888  Val accuracy: 99.9297%  Loss: 0.040665\n",
      "Epoch: 889  Val accuracy: 99.9385%  Loss: 0.040898\n",
      "Epoch: 890  Val accuracy: 99.9319%  Loss: 0.041304\n",
      "Epoch: 891  Val accuracy: 99.9341%  Loss: 0.039317\n",
      "Epoch: 892  Val accuracy: 99.9363%  Loss: 0.039513\n",
      "Epoch: 893  Val accuracy: 99.9319%  Loss: 0.040038\n",
      "Epoch: 894  Val accuracy: 99.9319%  Loss: 0.039961\n",
      "Epoch: 895  Val accuracy: 99.9319%  Loss: 0.040048\n",
      "Epoch: 896  Val accuracy: 99.9385%  Loss: 0.040769\n",
      "Epoch: 897  Val accuracy: 99.9363%  Loss: 0.039207\n",
      "Epoch: 898  Val accuracy: 99.9363%  Loss: 0.039138\n",
      "Epoch: 899  Val accuracy: 99.9363%  Loss: 0.039832\n",
      "Epoch: 900  Val accuracy: 99.9407%  Loss: 0.040801\n",
      "Epoch: 901  Val accuracy: 99.9363%  Loss: 0.039442\n",
      "Epoch: 902  Val accuracy: 99.9341%  Loss: 0.039475\n",
      "Epoch: 903  Val accuracy: 99.9363%  Loss: 0.038903\n",
      "Epoch: 904  Val accuracy: 99.9407%  Loss: 0.039650\n",
      "Epoch: 905  Val accuracy: 99.9341%  Loss: 0.039886\n",
      "Epoch: 906  Val accuracy: 99.9363%  Loss: 0.038816\n",
      "Epoch: 907  Val accuracy: 99.9319%  Loss: 0.039693\n",
      "Epoch: 908  Val accuracy: 99.9363%  Loss: 0.039054\n",
      "Epoch: 909  Val accuracy: 99.9385%  Loss: 0.039012\n",
      "Epoch: 910  Val accuracy: 99.9407%  Loss: 0.039632\n",
      "Epoch: 911  Val accuracy: 99.9341%  Loss: 0.039348\n",
      "Epoch: 912  Val accuracy: 99.9385%  Loss: 0.039944\n",
      "Epoch: 913  Val accuracy: 99.9341%  Loss: 0.039864\n",
      "Epoch: 914  Val accuracy: 99.9363%  Loss: 0.040481\n",
      "Epoch: 915  Val accuracy: 99.9363%  Loss: 0.040408\n",
      "Epoch: 916  Val accuracy: 99.9385%  Loss: 0.039506\n",
      "Epoch: 917  Val accuracy: 99.9363%  Loss: 0.039805\n",
      "Epoch: 918  Val accuracy: 99.9363%  Loss: 0.039311\n",
      "Epoch: 919  Val accuracy: 99.9385%  Loss: 0.040130\n",
      "Epoch: 920  Val accuracy: 99.9363%  Loss: 0.041311\n",
      "Epoch: 921  Val accuracy: 99.9363%  Loss: 0.039853\n",
      "Epoch: 922  Val accuracy: 99.9341%  Loss: 0.039745\n",
      "Epoch: 923  Val accuracy: 99.9363%  Loss: 0.040268\n",
      "Epoch: 924  Val accuracy: 99.9385%  Loss: 0.040762\n",
      "Epoch: 925  Val accuracy: 99.9341%  Loss: 0.038309\n",
      "Epoch: 926  Val accuracy: 99.9341%  Loss: 0.038847\n",
      "Epoch: 927  Val accuracy: 99.9385%  Loss: 0.040380\n",
      "Epoch: 928  Val accuracy: 99.9363%  Loss: 0.040939\n",
      "Epoch: 929  Val accuracy: 99.9429%  Loss: 0.038118\n",
      "Epoch: 930  Val accuracy: 99.9363%  Loss: 0.037904\n",
      "Epoch: 931  Val accuracy: 99.9341%  Loss: 0.039301     \n",
      "Epoch: 932  Val accuracy: 99.9341%  Loss: 0.039112\n",
      "Epoch: 933  Val accuracy: 99.9363%  Loss: 0.040867\n",
      "Epoch: 934  Val accuracy: 99.9385%  Loss: 0.040030\n",
      "Epoch: 935  Val accuracy: 99.9363%  Loss: 0.039514\n",
      "Epoch: 936  Val accuracy: 99.9363%  Loss: 0.039676\n",
      "Epoch: 937  Val accuracy: 99.9385%  Loss: 0.039739\n",
      "Epoch: 938  Val accuracy: 99.9341%  Loss: 0.040634\n",
      "Epoch: 939  Val accuracy: 99.9341%  Loss: 0.041185\n",
      "Epoch: 940  Val accuracy: 99.9319%  Loss: 0.047702\n",
      "Epoch: 941  Val accuracy: 99.9341%  Loss: 0.041495\n",
      "Epoch: 942  Val accuracy: 99.9363%  Loss: 0.038590\n",
      "Epoch: 943  Val accuracy: 99.9363%  Loss: 0.038496\n",
      "Epoch: 944  Val accuracy: 99.9363%  Loss: 0.038957\n",
      "Epoch: 945  Val accuracy: 99.9363%  Loss: 0.038379\n",
      "Epoch: 946  Val accuracy: 99.9363%  Loss: 0.039696\n",
      "Epoch: 947  Val accuracy: 99.9363%  Loss: 0.039893\n",
      "Epoch: 948  Val accuracy: 99.9341%  Loss: 0.039379\n",
      "Epoch: 949  Val accuracy: 99.9253%  Loss: 0.044611\n",
      "Epoch: 950  Val accuracy: 99.9363%  Loss: 0.039039\n",
      "Epoch: 951  Val accuracy: 99.9363%  Loss: 0.039345\n",
      "Epoch: 952  Val accuracy: 99.9363%  Loss: 0.039146\n",
      "Epoch: 953  Val accuracy: 99.9363%  Loss: 0.039689\n",
      "Epoch: 954  Val accuracy: 99.9341%  Loss: 0.040281\n",
      "Epoch: 955  Val accuracy: 99.9319%  Loss: 0.038745\n",
      "Epoch: 956  Val accuracy: 99.9341%  Loss: 0.040227\n",
      "Epoch: 957  Val accuracy: 99.9341%  Loss: 0.038550\n",
      "Epoch: 958  Val accuracy: 99.9363%  Loss: 0.039980\n",
      "Epoch: 959  Val accuracy: 99.9385%  Loss: 0.038781\n",
      "Epoch: 960  Val accuracy: 99.9319%  Loss: 0.038959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 961  Val accuracy: 99.9363%  Loss: 0.039876\n",
      "Epoch: 962  Val accuracy: 99.9319%  Loss: 0.040465\n",
      "Epoch: 963  Val accuracy: 99.9341%  Loss: 0.040126\n",
      "Epoch: 964  Val accuracy: 99.9319%  Loss: 0.044136\n",
      "Epoch: 965  Val accuracy: 99.9385%  Loss: 0.040312\n",
      "Epoch: 966  Val accuracy: 99.9363%  Loss: 0.038733\n",
      "Epoch: 967  Val accuracy: 99.9407%  Loss: 0.038550\n",
      "Epoch: 968  Val accuracy: 99.9363%  Loss: 0.038896\n",
      "Epoch: 969  Val accuracy: 99.9341%  Loss: 0.039369\n",
      "Epoch: 970  Val accuracy: 99.9363%  Loss: 0.039171\n",
      "Epoch: 971  Val accuracy: 99.9341%  Loss: 0.039845\n",
      "Epoch: 972  Val accuracy: 99.9363%  Loss: 0.040105\n",
      "Epoch: 973  Val accuracy: 99.9341%  Loss: 0.044983\n",
      "Epoch: 974  Val accuracy: 99.9363%  Loss: 0.040185\n",
      "Epoch: 975  Val accuracy: 99.9407%  Loss: 0.038938\n",
      "Epoch: 976  Val accuracy: 99.9363%  Loss: 0.039111\n",
      "Epoch: 977  Val accuracy: 99.9385%  Loss: 0.040539\n",
      "Epoch: 978  Val accuracy: 99.9385%  Loss: 0.039333\n",
      "Epoch: 979  Val accuracy: 99.9363%  Loss: 0.041821\n",
      "Epoch: 980  Val accuracy: 99.9341%  Loss: 0.041565\n",
      "Epoch: 981  Val accuracy: 99.9385%  Loss: 0.039172\n",
      "Epoch: 982  Val accuracy: 99.9341%  Loss: 0.041423\n",
      "Epoch: 983  Val accuracy: 99.9363%  Loss: 0.040910\n",
      "Epoch: 984  Val accuracy: 99.9319%  Loss: 0.041418\n",
      "Epoch: 985  Val accuracy: 99.9407%  Loss: 0.039565\n",
      "Epoch: 986  Val accuracy: 99.9341%  Loss: 0.040213\n",
      "Epoch: 987  Val accuracy: 99.9341%  Loss: 0.040193\n",
      "Epoch: 988  Val accuracy: 99.9363%  Loss: 0.039711\n",
      "Epoch: 989  Val accuracy: 99.9341%  Loss: 0.039423\n",
      "Epoch: 990  Val accuracy: 99.9363%  Loss: 0.039689\n",
      "Epoch: 991  Val accuracy: 99.9341%  Loss: 0.039855\n",
      "Epoch: 992  Val accuracy: 99.9341%  Loss: 0.040459\n",
      "Epoch: 993  Val accuracy: 99.9319%  Loss: 0.040098\n",
      "Epoch: 994  Val accuracy: 99.9341%  Loss: 0.040084\n",
      "Epoch: 995  Val accuracy: 99.9385%  Loss: 0.040636\n",
      "Epoch: 996  Val accuracy: 99.9341%  Loss: 0.040642\n",
      "Epoch: 997  Val accuracy: 99.9385%  Loss: 0.040636\n",
      "Epoch: 998  Val accuracy: 99.9363%  Loss: 0.040185\n",
      "Epoch: 999  Val accuracy: 99.9319%  Loss: 0.041490\n",
      "Epoch: 1000  Val accuracy: 99.9341%  Loss: 0.040834\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 500\n",
    "restore_checkpoint = False\n",
    "n_iterations_per_epoch = len(X_train) // batch_size\n",
    "n_iterations_validation = len(valX) // batch_size\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            X_batch = X_train[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "            y_batch = Y_train[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "            # Run the training operation and measure the loss:\n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={X: X_batch.reshape([-1, 5, 5, 1]),\n",
    "                           y: y_batch.reshape([-1]),\n",
    "                           mask_with_labels: True})\n",
    "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                      iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "            \n",
    "        # At the end of each epoch,  \n",
    "        # measure the validation loss and accuracy:\n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        for iteration in range(1, n_iterations_validation + 1):\n",
    "            X_batch = valX[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "            y_batch = valY[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "            loss_val, acc_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch.reshape([-1, 5, 5, 1]),\n",
    "                               y: y_batch.reshape([-1])})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "        # And save the model if it improved: \n",
    "        \n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network\n",
      "Final test accuracy: 99.9345%  Loss: 0.016660   \n"
     ]
    }
   ],
   "source": [
    "n_iterations_test = len(testX) // batch_size\n",
    "checkpoint_path = \"./my_capsule_network\"\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    pred = []\n",
    "    loss_tests = []\n",
    "    acc_tests = []\n",
    "    for iteration in range(1, n_iterations_test + 1):\n",
    "        X_batch = testX[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "        y_batch = testY[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "        loss_test, acc_test = sess.run(\n",
    "                [loss, accuracy],\n",
    "                feed_dict={X: X_batch.reshape([-1, 5, 5, 1]),\n",
    "                           y: y_batch.reshape([-1])})\n",
    "        loss_tests.append(loss_test)\n",
    "        pred.append(y_pred)\n",
    "        acc_tests.append(acc_test)\n",
    "        print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                  iteration, n_iterations_test,\n",
    "                  iteration * 100 / n_iterations_test),\n",
    "              end=\" \" * 10)\n",
    "    loss_test = np.mean(loss_tests)\n",
    "    #print(tf.confusion_matrix())\n",
    "    acc_test = np.mean(acc_tests)\n",
    "    print(\"\\rFinal test accuracy: {:.4f}%  Loss: {:.6f}\".format(\n",
    "        acc_test * 100, loss_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[181939     22]\n",
      " [    64    251]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    181961\n",
      "          1       0.92      0.80      0.85       315\n",
      "\n",
      "avg / total       1.00      1.00      1.00    182276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: X_train.reshape([-1, 5, 5, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "Y_train = Y_train.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(Y_train, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(Y_train, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[45486     4]\n",
      " [   26    53]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.93      0.67      0.78        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: valX.reshape([-1, 5, 5, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "valY = valY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(valY, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(valY, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[56851    13]\n",
      " [   24    74]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     56864\n",
      "          1       0.85      0.76      0.80        98\n",
      "\n",
      "avg / total       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: testX.reshape([-1, 5, 5, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "testY = testY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(testY, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(testY, pred, labels=None, sample_weight=None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
