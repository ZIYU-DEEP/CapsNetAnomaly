{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inderjeet78/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report,accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time','Amount'],axis=1)\n",
    "X = data.iloc[:,data.columns != 'Class']\n",
    "Y = data.iloc[:,data.columns == 'Class']\n",
    "pca = PCA(n_components=25)\n",
    "X = pca.fit_transform(X)\n",
    "X_train,testX,Y_train,testY = train_test_split(X,Y,test_size=0.20,random_state=21, stratify=Y)\n",
    "X_train,valX,Y_train,valY = train_test_split(X_train,Y_train,test_size=0.20,random_state=21, stratify=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "valX = np.array(valX)\n",
    "testX = np.array(testX)\n",
    "Y_train = np.array(Y_train)\n",
    "valY = np.array(valY)\n",
    "testY = np.array(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = XGBClassifier()\n",
    "param_grid = {'learning_rate':np.arange(0.01,0.5,0.1),'n_estimators': range(50,100),'min_child_weight':range(2,4),\n",
    "              'gamma': range(0,3)}\n",
    "CV_lr = GridSearchCV(estimator=xg,param_grid=param_grid,cv=5,scoring='f1',n_jobs=-1)\n",
    "CV_lr.fit(X=X_train,y=Y_train)\n",
    "best_param = CV_lr.best_params_\n",
    "print(\"Best Paramters for 50/50 Splits: \",best_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on train set is:  0.9994294366784436\n",
      "Score for test data is 0.9995786664794073\n",
      "Classification report for train set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.96      0.70      0.81        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45569\n",
      "\n",
      "Confusion matrix for train set\n",
      "[[45488     2]\n",
      " [   24    55]]\n",
      "Confusion matrix for train set\n",
      "[[56858     6]\n",
      " [   18    80]]\n",
      "Classification report for test set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     56864\n",
      "          1       0.93      0.82      0.87        98\n",
      "\n",
      "avg / total       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg = XGBClassifier(n_estimators=70,learning_rate=0.31, gamma=0, min_child_weight=2)\n",
    "xg.fit(X_train,Y_train)\n",
    "y_pred1 = xg.predict(valX)\n",
    "y_pred2 = xg.predict(testX)\n",
    "print (\"Score on train set is: \", accuracy_score(valY,y_pred1))\n",
    "print (\"Score for test data is\", accuracy_score(testY,y_pred2))\n",
    "print(\"Classification report for train set\")\n",
    "print(classification_report(valY,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(valY,y_pred1))\n",
    "print(\"Confusion matrix for train set\")\n",
    "print(confusion_matrix(testY,y_pred2))\n",
    "print(\"Classification report for test set\")\n",
    "print(classification_report(testY,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
