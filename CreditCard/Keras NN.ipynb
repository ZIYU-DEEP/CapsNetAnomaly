{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inderjeet78/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.reset_default_graph()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report,accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time','Amount'],axis=1)\n",
    "X = data.iloc[:,data.columns != 'Class']\n",
    "Y = data.iloc[:,data.columns == 'Class']\n",
    "pca = PCA(n_components=25)\n",
    "X = pca.fit_transform(X)\n",
    "X_train,testX,Y_train,testY = train_test_split(X,Y,test_size=0.20,random_state=21, stratify=Y)\n",
    "X_train,valX,Y_train,valY = train_test_split(X_train,Y_train,test_size=0.20,random_state=21, stratify=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "valX = np.array(valX)\n",
    "testX = np.array(testX)\n",
    "Y_train = np.array(Y_train)\n",
    "valY = np.array(valY)\n",
    "testY = np.array(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "182276/182276 [==============================] - 2s 13us/step - loss: 0.0302 - acc: 0.9929\n",
      "Epoch 2/10\n",
      "182276/182276 [==============================] - 2s 9us/step - loss: 0.0032 - acc: 0.9994\n",
      "Epoch 3/10\n",
      "182276/182276 [==============================] - 2s 9us/step - loss: 0.0029 - acc: 0.9994\n",
      "Epoch 4/10\n",
      "182276/182276 [==============================] - 2s 9us/step - loss: 0.0027 - acc: 0.9994\n",
      "Epoch 5/10\n",
      "182276/182276 [==============================] - 2s 10us/step - loss: 0.0026 - acc: 0.9994\n",
      "Epoch 6/10\n",
      "182276/182276 [==============================] - 2s 10us/step - loss: 0.0025 - acc: 0.9994\n",
      "Epoch 7/10\n",
      "182276/182276 [==============================] - 2s 9us/step - loss: 0.0024 - acc: 0.9994\n",
      "Epoch 8/10\n",
      "182276/182276 [==============================] - 2s 9us/step - loss: 0.0023 - acc: 0.9994\n",
      "Epoch 9/10\n",
      "182276/182276 [==============================] - 2s 8us/step - loss: 0.0022 - acc: 0.9995\n",
      "Epoch 10/10\n",
      "182276/182276 [==============================] - 2s 9us/step - loss: 0.0021 - acc: 0.9995\n",
      "45569/45569 [==============================] - 1s 23us/step\n",
      "\n",
      "acc: 99.94%\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=25, activation='relu'))\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=256)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(valX, valY)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model.predict(testX)\n",
    "predictionst = model.predict(X_train)\n",
    "predictionsval = model.predict(valX)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "rounded2 = [round(x[0]) for x in predictionst]\n",
    "roundedval = [round(x[0]) for x in predictionsval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc auc score is :  0.9268577262718865\n",
      "Accuracy :  0.9994952709078541\n",
      "Classification report is : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    181961\n",
      "          1       0.85      0.85      0.85       315\n",
      "\n",
      "avg / total       1.00      1.00      1.00    182276\n",
      "\n",
      "Confusion Matrix for test set is : \n",
      "[[181915     46]\n",
      " [    46    269]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train roc auc score is : \", roc_auc_score(Y_train,rounded2))\n",
    "print(\"Accuracy : \",accuracy_score(Y_train,rounded2))\n",
    "print(\"Classification report is : \")\n",
    "print(classification_report(Y_train, rounded2))\n",
    "print(\"Confusion Matrix for test set is : \")\n",
    "print(confusion_matrix(Y_train,rounded2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test roc auc score is :  0.8796698954562276\n",
      "Accuracy :  0.9994294366784436\n",
      "Classification report is : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.90      0.76      0.82        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45569\n",
      "\n",
      "Confusion Matrix for test set is : \n",
      "[[45483     7]\n",
      " [   19    60]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test roc auc score is : \", roc_auc_score(valY,roundedval))\n",
    "print(\"Accuracy : \",accuracy_score(valY,roundedval))\n",
    "print(\"Classification report is : \")\n",
    "print(classification_report(valY,roundedval))\n",
    "print(\"Confusion Matrix for test set is : \")\n",
    "print(confusion_matrix(valY,roundedval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test roc auc score is :  0.923346287023532\n",
      "Accuracy :  0.9994908886626171\n",
      "Classification report is : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     56864\n",
      "          1       0.86      0.85      0.85        98\n",
      "\n",
      "avg / total       1.00      1.00      1.00     56962\n",
      "\n",
      "Confusion Matrix for test set is : \n",
      "[[56850    14]\n",
      " [   15    83]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test roc auc score is : \", roc_auc_score(testY,rounded))\n",
    "print(\"Accuracy : \",accuracy_score(testY,rounded))\n",
    "print(\"Classification report is : \")\n",
    "print(classification_report(testY, rounded))\n",
    "print(\"Confusion Matrix for test set is : \")\n",
    "print(confusion_matrix(testY,rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
