{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inderjeet78/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.reset_default_graph()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time','Amount'],axis=1)\n",
    "X = data.iloc[:,data.columns != 'Class']\n",
    "Y = data.iloc[:,data.columns == 'Class']\n",
    "pca = PCA(n_components=25)\n",
    "X = pca.fit_transform(X)\n",
    "X_train,testX,Y_train,testY = train_test_split(X,Y,test_size=0.20,random_state=21, stratify=Y)\n",
    "X_train,valX,Y_train,valY = train_test_split(X_train,Y_train,test_size=0.20,random_state=21, stratify=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "valX = np.array(valX)\n",
    "testX = np.array(testX)\n",
    "Y_train = np.array(Y_train)\n",
    "valY = np.array(valY)\n",
    "testY = np.array(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-b8bf15cf34fb>:32: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From <ipython-input-4-b8bf15cf34fb>:67: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(shape=[None, 5, 5, 1], dtype=tf.float32, name=\"X\")\n",
    "\n",
    "caps1_n_maps = 8\n",
    "caps1_n_caps = caps1_n_maps * 4 * 4  # 1152 primary capsules\n",
    "caps1_n_dims = 4\n",
    "\n",
    "conv1_params = {\n",
    "    \"filters\": 32,\n",
    "    \"kernel_size\": 2,\n",
    "    \"strides\": 1,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu,\n",
    "}\n",
    "\n",
    "\"\"\"conv2_params = {\n",
    "    \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
    "    \"kernel_size\": 9,\n",
    "    \"strides\": 2,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\"\"\"\n",
    "\n",
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
    "#conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)\n",
    "\n",
    "caps1_raw = tf.reshape(conv1, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                       name=\"caps1_raw\")\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector\n",
    "\n",
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")\n",
    "\n",
    "caps2_n_caps = 2\n",
    "caps2_n_dims = 6\n",
    "\n",
    "init_sigma = 0.1\n",
    "\n",
    "W_init = tf.random_normal(\n",
    "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "W = tf.Variable(W_init, name=\"W\")\n",
    "\n",
    "batch_size = tf.shape(X)[0]\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")\n",
    "\n",
    "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                       name=\"caps1_output_expanded\")\n",
    "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                   name=\"caps1_output_tile\")\n",
    "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                             name=\"caps1_output_tiled\")\n",
    "\n",
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
    "                            name=\"caps2_predicted\")\n",
    "\n",
    "# Dynamic Routing algorithm\n",
    "# Round 1\n",
    "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
    "                       dtype=np.float32, name=\"raw_weights\")\n",
    "routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")\n",
    "\n",
    "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
    "                                   name=\"weighted_predictions\")\n",
    "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
    "                             name=\"weighted_sum\")\n",
    "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
    "                              name=\"caps2_output_round_1\")\n",
    "\n",
    "caps2_output_round_1_tiled = tf.tile(\n",
    "    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_1_tiled\")\n",
    "\n",
    "agreement1 = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
    "                      transpose_a=True, name=\"agreement1\")\n",
    "# Round 2\n",
    "# Routing weight update\n",
    "raw_weights_round_2 = tf.add(raw_weights, agreement1,\n",
    "                             name=\"raw_weights_round_2\")\n",
    "routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_2\")\n",
    "weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_2\")\n",
    "weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_2\")\n",
    "caps2_output_round_2 = squash(weighted_sum_round_2,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_2\")\n",
    "caps2_output_round_2_tiled = tf.tile(\n",
    "    caps2_output_round_2, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_2_tiled\")\n",
    "\n",
    "agreement2 = tf.matmul(caps2_predicted, caps2_output_round_2_tiled,\n",
    "                      transpose_a=True, name=\"agreement2\")\n",
    "\n",
    "# Round 3\n",
    "# Routing weight update\n",
    "raw_weights_round_3 = tf.add(raw_weights_round_2, agreement2,\n",
    "                             name=\"raw_weights_round_3\")\n",
    "routing_weights_round_3 = tf.nn.softmax(raw_weights_round_3,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_3\")\n",
    "weighted_predictions_round_3 = tf.multiply(routing_weights_round_3,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_3\")\n",
    "weighted_sum_round_3 = tf.reduce_sum(weighted_predictions_round_3,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_3\")\n",
    "caps2_output_round_3 = squash(weighted_sum_round_3,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_3\")\n",
    "caps2_output_round_3_tiled = tf.tile(\n",
    "    caps2_output_round_3, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_3_tiled\")\n",
    "\n",
    "agreement3 = tf.matmul(caps2_predicted, caps2_output_round_3_tiled,\n",
    "                      transpose_a=True, name=\"agreement3\")\n",
    "\n",
    "# Round 4\n",
    "# Routing weight update\n",
    "raw_weights_round_4 = tf.add(raw_weights_round_3, agreement3,\n",
    "                             name=\"raw_weights_round_4\")\n",
    "routing_weights_round_4 = tf.nn.softmax(raw_weights_round_4,\n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights_round_4\")\n",
    "weighted_predictions_round_4 = tf.multiply(routing_weights_round_4,\n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions_round_4\")\n",
    "weighted_sum_round_4 = tf.reduce_sum(weighted_predictions_round_4,\n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum_round_4\")\n",
    "caps2_output_round_4 = squash(weighted_sum_round_4,\n",
    "                              axis=-2,\n",
    "                              name=\"caps2_output_round_4\")\n",
    "\"\"\"caps2_output_round_4_tiled = tf.tile(\n",
    "    caps2_output_round_4, [1, caps1_n_caps, 1, 1, 1],\n",
    "    name=\"caps2_output_round_4_tiled\")\n",
    "\n",
    "agreement4 = tf.matmul(caps2_predicted, caps2_output_round_4_tiled,\n",
    "                      transpose_a=True, name=\"agreement3\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "caps2_output = caps2_output_round_4\n",
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)\n",
    "\n",
    "y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")\n",
    "\n",
    "\n",
    "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n",
    "\n",
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
    "\n",
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")\n",
    "\n",
    "m_plus = 0.95\n",
    "m_minus = 0.1\n",
    "lambda_ = 100\n",
    "\n",
    "T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")\n",
    "\n",
    "caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
    "                              name=\"caps2_output_norm\")\n",
    "\n",
    "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
    "                              name=\"present_error_raw\")\n",
    "present_error = tf.reshape(present_error_raw, shape=(-1, 2),\n",
    "                           name=\"present_error\")\n",
    "present_error\n",
    "\n",
    "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
    "                             name=\"absent_error_raw\")\n",
    "absent_error = tf.reshape(absent_error_raw, shape=(-1, 2),\n",
    "                          name=\"absent_error\")\n",
    "\n",
    "# Loss Function\n",
    "\n",
    "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
    "           name=\"L\")\n",
    "\n",
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n",
    "\n",
    "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
    "                                               name=\"mask_with_labels\")\n",
    "\n",
    "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                                 lambda: y,        # if True\n",
    "                                 lambda: y_pred,   # if False\n",
    "                                 name=\"reconstruction_targets\")\n",
    "\n",
    "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
    "                                 depth=caps2_n_caps,\n",
    "                                 name=\"reconstruction_mask\")\n",
    "\n",
    "reconstruction_mask_reshaped = tf.reshape(\n",
    "    reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],\n",
    "    name=\"reconstruction_mask_reshaped\")\n",
    "\n",
    "caps2_output_masked = tf.multiply(\n",
    "    caps2_output, reconstruction_mask_reshaped,\n",
    "    name=\"caps2_output_masked\")\n",
    "\n",
    "decoder_input = tf.reshape(caps2_output_masked,\n",
    "                           [-1, caps2_n_caps * caps2_n_dims],\n",
    "                           name=\"decoder_input\")\n",
    "\n",
    "n_hidden1 = 16\n",
    "n_hidden2 = 32\n",
    "n_output = 5*5\n",
    "\n",
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
    "                                     activation=tf.nn.sigmoid,\n",
    "                                     name=\"decoder_output\")\n",
    "\n",
    "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "squared_difference = tf.square(X_flat - decoder_output,\n",
    "                               name=\"squared_difference\")\n",
    "reconstruction_loss = tf.reduce_mean(squared_difference,\n",
    "                                    name=\"reconstruction_loss\")\n",
    "\n",
    "alpha = 0.0005\n",
    "\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")\n",
    "\n",
    "\n",
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Val accuracy: 99.8527%  Loss: 0.041566 (improved)\n",
      "Epoch: 2  Val accuracy: 99.8945%  Loss: 0.031954 (improved)\n",
      "Epoch: 3  Val accuracy: 99.8835%  Loss: 0.026537 (improved)\n",
      "Epoch: 4  Val accuracy: 99.8857%  Loss: 0.025112 (improved)\n",
      "Epoch: 5  Val accuracy: 99.9165%  Loss: 0.024368 (improved)\n",
      "Epoch: 6  Val accuracy: 99.9055%  Loss: 0.024444\n",
      "Epoch: 7  Val accuracy: 99.9077%  Loss: 0.023807 (improved)\n",
      "Epoch: 8  Val accuracy: 99.9297%  Loss: 0.023319 (improved)\n",
      "Epoch: 9  Val accuracy: 99.9297%  Loss: 0.023025 (improved)\n",
      "Epoch: 10  Val accuracy: 99.9319%  Loss: 0.022786 (improved)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 500\n",
    "restore_checkpoint = False\n",
    "n_iterations_per_epoch = len(X_train) // batch_size\n",
    "n_iterations_validation = len(valX) // batch_size\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            X_batch = X_train[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "            y_batch = Y_train[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "            # Run the training operation and measure the loss:\n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={X: X_batch.reshape([-1, 5, 5, 1]),\n",
    "                           y: y_batch.reshape([-1]),\n",
    "                           mask_with_labels: True})\n",
    "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                      iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "            \n",
    "        # At the end of each epoch,  \n",
    "        # measure the validation loss and accuracy:\n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        for iteration in range(1, n_iterations_validation + 1):\n",
    "            X_batch = valX[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "            y_batch = valY[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "            loss_val, acc_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch.reshape([-1, 5, 5, 1]),\n",
    "                               y: y_batch.reshape([-1])})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "        # And save the model if it improved: \n",
    "        \n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network\n",
      "Final test accuracy: 99.9345%  Loss: 0.016493   \n"
     ]
    }
   ],
   "source": [
    "n_iterations_test = len(testX) // batch_size\n",
    "checkpoint_path = \"./my_capsule_network\"\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    pred = []\n",
    "    loss_tests = []\n",
    "    acc_tests = []\n",
    "    for iteration in range(1, n_iterations_test + 1):\n",
    "        X_batch = testX[(iteration-1)*batch_size:(iteration*batch_size),:]\n",
    "        y_batch = testY[(iteration-1)*batch_size:(iteration*batch_size)]\n",
    "        loss_test, acc_test = sess.run(\n",
    "                [loss, accuracy],\n",
    "                feed_dict={X: X_batch.reshape([-1, 5, 5, 1]),\n",
    "                           y: y_batch.reshape([-1])})\n",
    "        loss_tests.append(loss_test)\n",
    "        pred.append(y_pred)\n",
    "        acc_tests.append(acc_test)\n",
    "        print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                  iteration, n_iterations_test,\n",
    "                  iteration * 100 / n_iterations_test),\n",
    "              end=\" \" * 10)\n",
    "    loss_test = np.mean(loss_tests)\n",
    "    #print(tf.confusion_matrix())\n",
    "    acc_test = np.mean(acc_tests)\n",
    "    print(\"\\rFinal test accuracy: {:.4f}%  Loss: {:.6f}\".format(\n",
    "        acc_test * 100, loss_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[181927     34]\n",
      " [    65    250]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    181961\n",
      "          1       0.88      0.79      0.83       315\n",
      "\n",
      "avg / total       1.00      1.00      1.00    182276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: X_train.reshape([-1, 5, 5, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "Y_train = Y_train.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(Y_train, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(Y_train, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[45485     5]\n",
      " [   26    53]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.91      0.67      0.77        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: valX.reshape([-1, 5, 5, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "valY = valY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(valY, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(valY, pred, labels=None, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_capsule_network\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[56853    11]\n",
      " [   26    72]]\n",
      "\n",
      "Classification report is : \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     56864\n",
      "          1       0.87      0.73      0.80        98\n",
      "\n",
      "avg / total       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    y_pred_value = sess.run(\n",
    "            [y_pred],\n",
    "            feed_dict={X: testX.reshape([-1, 5, 5, 1]),\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "pred = np.array(y_pred_value).T\n",
    "pred = pred.flatten()\n",
    "testY = testY.flatten()\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix is :\")\n",
    "print(confusion_matrix(testY, pred, labels=None, sample_weight=None))\n",
    "print(\"\")\n",
    "print(\"Classification report is : \")\n",
    "print(\"\")\n",
    "print(classification_report(testY, pred, labels=None, sample_weight=None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
